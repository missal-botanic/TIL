{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e571f3a0-c096-4ae9-aa2b-129c896a602b",
   "metadata": {},
   "source": [
    "# CH03 LLM,RAG 개인 필수 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b44fd0-0f5b-481d-9551-0966e20f6cba",
   "metadata": {},
   "source": [
    "### 01_API key_load_환경변수(environment_variables)사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2970b43a-7ba1-48e6-8b0f-58f5b0c02ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes key\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일을 불러오기\n",
    "load_dotenv(r\"C:\\Users\\241011\\Documents\\key.env\")\n",
    "\n",
    "# 환경 변수 중 하나를 확인 (예: 'KEY'라는 환경 변수 확인)\n",
    "key = os.getenv(\"GOOGLE_API_KEY\")  # 여기서 \"KEY\"는 .env 파일에 정의된 환경 변수의 이름입니다.\n",
    "\n",
    "# 환경 변수가 존재하는지 확인\n",
    "if key:  # key 값이 존재하면 True, 존재하지 않으면 False\n",
    "    print(\"yes key\")\n",
    "else:\n",
    "    print(\"no key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f365f28-fc29-4c00-b7ad-3d6173a2ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 경로가 올바릅니다!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# PDF 경로 확인\n",
    "pdf_path = r\"C:\\Users\\241011\\Documents\\TIL\\00_Class\\03_RAG\\00_data\\인공지능산업최신동향_2024년11월호.pdf\"\n",
    "\n",
    "if os.path.exists(pdf_path):\n",
    "    print(\"파일 경로가 올바릅니다!\")\n",
    "else:\n",
    "    print(\"파일을 찾을 수 없습니다. 경로를 다시 확인하세요.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45104ad9-5f5c-4d6e-a03a-2ae5509dfce0",
   "metadata": {},
   "source": [
    "### 02_PDF loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b12d0b3-bedb-4077-819c-814c71c7db2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▹ 미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발\n",
      "\n",
      "위원회에 따르면 연방정부와 법 집행기관에서 얼굴인식 기술이 빠르게 도입되\n",
      "대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을  지원하\n",
      "르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오  분\n",
      " AI 도입 모범사례와 거버넌스 프레임워크,  정책 옵션을 토대로 공공 \n",
      "입안자를 대상으로 생성AI의 공익적 활용과 경제사회적  균형 달성, 위험\n",
      " 2024년 3분기 AI 스타트업은 전체 벤처 투자의 31%를 유치했으며\n",
      "동영상 제작, 동영상 편집, 오디오 생성과 같은 기능을 지원하는  ‘메타\n",
      "두 처리할 수 있는 모델과 모바일 기기에서 실행 가능한 경량  모델을 포\n",
      "모’ 공개 n 앨런AI연구소가 공개한 멀티모달 LLM 제품군 몰모는 벤치\n",
      "스로 사용할 수 있는 경량 모델 ‘레 미니스트로’를  미스트랄 3B와 미\n",
      " 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 A\n",
      " 바탕으로 인공 신경망을 이용한 머신러닝의 토대가 되는  방법을 개발한 \n",
      "국 국무부는 바이든 대통령의 AI 행정명령에 따라 국제협력을 통해 포괄적\n",
      "공자가 안전성 평가에 참조할 수 있는 ‘AI 안전성에 대한  평가 관점 \n",
      "마인드가 강화학습 방식으로 반도체 칩 레이아웃을 설계하여 사람이 몇 주에\n",
      "1의 오리 고센 CEO는 AI 모델 개발에 주로 활용되는 트랜스포머  아\n",
      "터가 설문조사를 통해 근로자 관점의 자동화 기술의 영향을 조사한 결과, \n",
      " 2025년 이직을 계획 중이며, 58%는 2024년 중 현재보다  더 \n",
      "따르면 생성AI의 도입으로 중장기적으로 소프트웨어 엔지니어링에서 데이터 \n",
      "에 대한 생성AI의 수행 능력을 분석해 인간을 대체할  가능성을 평가한 \n",
      "리 법인으로 매년 학제간  학술대회(NeurIPS)를 주최 - 이번 제3\n",
      " Seongnam-si, Gyeonggi-do, Republic of K\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.schema import Document\n",
    "from typing import List\n",
    "\n",
    "# PDF 파일 로드 (PyMuPDF 사용)\n",
    "def extract_text_from_pdf(pdf_path: str) -> List[str]:\n",
    "    \"\"\"PyMuPDF를 사용하여 PDF에서 각 페이지의 텍스트를 추출\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text_pages = []\n",
    "    \n",
    "    # 각 페이지에서 텍스트 추출\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text(\"text\")\n",
    "        text_pages.append(text)\n",
    "    \n",
    "    return text_pages\n",
    "\n",
    "# 줄바꿈 제거 함수\n",
    "def remove_newlines_except_after_period(text: str) -> str:\n",
    "    \"\"\"마침표 다음의 줄바꿈을 제외한 모든 줄바꿈을 제거\"\"\"\n",
    "    return re.sub(r'(?<!\\.)(\\n|\\r\\n)', ' ', text)\n",
    "\n",
    "# 연속된 '·' 문자와 숫자 뒤 텍스트 제거하는 함수\n",
    "def remove_page_numbers_and_bullet_points(text: str) -> str:\n",
    "    \"\"\"페이지 번호와 구분 기호 ···· 등 제거\"\"\"\n",
    "    # 숫자, 특수문자(·) 뒤에 이어지는 텍스트를 제거\n",
    "    text = re.sub(r'\\d+\\s*▹\\s*[\\u25CB\\u2022\\u2023]*\\s*\\d+', '', text)  # 페이지 번호나 번호 뒤 '·' 제거\n",
    "    text = re.sub(r'·+', '', text)  # 연속된 '·' 제거\n",
    "    return text\n",
    "\n",
    "# 페이지 처리 함수\n",
    "def process_pdf(pdf_path: str) -> List[Document]:\n",
    "    pages_text = extract_text_from_pdf(pdf_path)  # PDF에서 텍스트 추출\n",
    "    \n",
    "    processed_documents = []\n",
    "    \n",
    "    for page_text in pages_text:\n",
    "        # 텍스트에서 불필요한 줄바꿈 제거\n",
    "        cleaned_text = remove_newlines_except_after_period(page_text)\n",
    "        \n",
    "        # 페이지 번호와 구분 기호 제거\n",
    "        cleaned_text = remove_page_numbers_and_bullet_points(cleaned_text)\n",
    "        \n",
    "        # 처리된 페이지 정보를 새로운 Document로 저장\n",
    "        processed_documents.append(Document(page_content=cleaned_text, metadata={}))\n",
    "    \n",
    "    return processed_documents\n",
    "\n",
    "# PDF 파일 처리\n",
    "pdf_path = r\"C:\\Users\\241011\\Documents\\TIL\\00_Class\\03_RAG\\00_data\\인공지능산업최신동향_2024년11월호.pdf\"\n",
    "pages = process_pdf(pdf_path)\n",
    "\n",
    "# 결과 출력 (예시)\n",
    "for doc in pages:\n",
    "    print(doc.page_content[90:130])  # 처리된 텍스트 일부 출력\n",
    "\n",
    "#print(f'type : {type(pages)} / len : {len(pages)} / pages : {pages}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7bfebb-ff81-4179-b422-1af49b515300",
   "metadata": {},
   "source": [
    "### 03_TextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9b3fde-d7ae-406a-9860-022961067c09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_size:\n",
      "[10, 1084, 17, 1542, 1567, 1547, 1523, 1568, 1488, 1451, 1673, 1378, 1351, 1460, 1727, 1587, 1594, 1406, 1620, 1430]\n",
      "====================================================================================================\n",
      "Chunk 1: page_content='2024년 11월호'\n",
      "Chunk 2: page_content='2024년 11월호 Ⅰ. 인공지능 산업 동향 브리프  1. 정책/법제     ▹ 미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석 1    ▹ 미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표 2    ▹ 유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간 3    ▹ OECD, 공공 부문의 AI 도입을 위한 G7 툴킷 발표 4    ▹ 세계경제포럼, 생성AI 시대의 거버넌스 프레임워크 제시 5    2. 기업/산업     ▹ CB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중 6    ▹ 메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개 7    ▹ 메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개 8    ▹ 앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개 9    ▹ 미스트랄AI, 온디바이스용 AI 모델 ‘레 미니스트로’ 공개 10    ▹ 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개 11  3. 기술/연구    ▹ 2024년 노벨 물리학상과 화학상, AI 관련 연구자들이 수상 12    ▹ 미국 국무부, AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표 13    ▹ 일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간 14    ▹ 구글 딥마인드, 반도체 칩 레이아웃 설계하는 AI 모델 ‘알파칩’ 발표 15    ▹ AI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조 16      4. 인력/교육         ▹ MIT 산업성과센터, 근로자 관점에서 자동화 기술의 영향 조사 17    ▹ 다이스 조사, AI 전문가의 73%는 2025년 중 이직 고려 18    ▹ 가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요  19    ▹ 인디드 조사 결과, 생성AI가 인간 근로자 대체할 가능성은 희박 20      Ⅱ. 주요 행사   ▹NeurIPS 2024  21   ▹GenAI Summit Maroc 2024  21   ▹AI Summit Seoul 2024  21'\n",
      "Chunk 3: page_content='Ⅰ. 인공지능 산업 동향 브리프'\n",
      "Chunk 4: page_content='1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 1 미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석 n 미국 민권위원회에 따르면 연방정부와 법 집행기관에서 얼굴인식 기술이 빠르게 도입되고  있으나 이를 관리할 지침과 감독의 부재로 민권 문제를 초래할 위험 존재 n 미국 민권위원회는 연방정부의 책임 있는 얼굴인식 기술 사용을 위해 운영 프로토콜 개발과  실제 사용 상황의 얼굴인식 기술 평가 및 불평등 완화, 지역사회의 의견 수렴 등을 권고 KEY Contents £ 연방정부의 얼굴인식 기술 도입에 대한 지침과 감독 부재로 민권 문제를 초래할 위험 존재 n 미국 민권위원회(U.S. Commission on Civil Rights)가 2024년 9월 19일 연방정부의 얼굴인식  기술 사용이 민권에 미치는 영향을 분석한 보고서를 발간 ∙AI 기술의 일종인 얼굴인식 기술은 연방정부와 법 집행기관에서 빠르게 도입되고 있으며, 일례로  법무부 연방수사국(FBI)은 범죄 수사 및 용의자 수색용 단서 확보를 위해 얼굴인식 기술을 가장 빈번히 사용 ∙그러나 얼굴인식 기술의 책임 있는 사용을 위한 연방 지침과 감독은 실제 활용 사례보다 뒤처졌으며,  현재 연방정부의 얼굴인식 기술이나 여타 AI 기술 사용을 명시적으로 규제하는 법률도 부재   n 보고서에 따르면 얼굴인식 기술의 무분별한 사용은 편향, 개인정보 침해, 적법 절차의 미준수  및 차별적 영향과 같은 민권 문제를 초래할 위험 보유 ∙얼굴인식 기술의 정확도는 인종, 성별, 연령 등 인구통계학적 요인에 따라 달라질 수 있으며, 이는 식별  오류 및 부정확한 체포로 이어져 유색인종을 비롯한 특정 집단에 차별적 결과를 초래할 위험 존재 ∙정부 기관이 사전 영장이나 정당한 이유 없이 얼굴인식 기술을 광범위하게 사용할 경우 개인을  지속적으로 추적하고 감시함으로써 개인정보 보호 권리에 심각한 영향을 미칠 위험 존재 ∙법 집행기관의 얼굴인식 기술 사용 시 부정확한 식별 및 편향으로 인해 개인이 법의 보호를 받아  공정하고 올바르게 대우받을 권리를 침해할 가능성도 존재 £ 민권위원회, 연방정부의 책임 있는 얼굴인식 기술 사용을 위한 권고사항 제시 n 민권위원회는 연방정부의 얼굴인식 기술 사용과 관련해 다음과 같은 권고사항을 제시 ∙국립표준기술연구소(NIST)는 정부 기관의 얼굴인식 기술 시스템 도입 시의 효과와 공평성, 정확성  평가에 사용할 수 있는 운영 테스트 프로토콜의 개발 필요 ∙각 연방정부 기관의 최고AI책임자는 실제 사용 상황에서 얼굴인식 기술을 평가하고 차별이나 편견으로  인한 불평등을 완화하며, 얼굴인식 기술의 사용으로 영향을 받는 지역사회의 의견을 수렴 필요 ∙얼굴인식 기술 제공업체는 다양한 인구통계 집단에 대한 높은 정확도를 보장하기 위해 지속적인 교육과  지원, 업데이트를 제공 필요  ☞ 출처: U.S. Commission on Civil Rights, The Civil Rights Implications of the Federal Use of Facial Recognition Technology, 2024.09.19.'\n",
      "Chunk 5: page_content='SPRi AI Brief |   2024-11월호 2 미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표 n 미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을  지원하기 위한 지침을 발표  n 지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI  솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구   KEY Contents £ 백악관 예산관리국, 연방정부의 AI 조달 시 책임성을 증진하기 위한 모범 관행 제시 n 미국 백악관 예산관리국(OMB)이 바이든 대통령의 AI 행정명령에 따른 후속 조치로 2024년 10월 3일  ‘정부의 책임 있는 AI 조달 지침(M-24-18)’을 발표 ∙미국 연방정부는 2023년 1,000억 달러 이상의 IT 제품과 서비스를 구매한 미국 경제 최대 규모의 단일  구매자로서 구매력을 활용해 책임 있는 AI의 발전을 뒷받침할 계획 ∙이번 지침은 △AI 위험과 성과 관리 △AI 시장의 경쟁 촉진 △연방정부 전반의 협업 보장이라는 3개  전략적 목표에 대하여 권고사항을 제시 n (AI 위험과 성과 관리) 예산관리국의 지침은 AI 시스템의 구축, 훈련, 배포 방식의 복잡성을 고려해  AI의 위험과 성과를 관리하기 위한 모범 관행을 다음과 같이 제시 ∙정부 기관의 개인정보 보호 담당자가 AI 조달 프로세스에 조기에 지속적으로 참여해 개인정보 보호  위험을 식별 및 관리하고 법률과 정책 준수를 보장 ∙정부 기관과 공급업체와 간 협력으로 AI 솔루션이 조달되는 시기와 해당 조달로 인해 시민 권리와  안전에 영향을 미치는 AI에 대하여 추가로 위험관리가 필요한 시점을 파악 ∙성과 기반의 혁신적 조달 기법을 활용해 정부 기관이 위험을 효과적으로 관리 및 완화하고 성과를 향상할  수 있도록 장려하는 한편, 정부 데이터와 지식재산권을 보호하는 방식으로 계약 조건을 협상  n (AI 시장의 경쟁 촉진) 지침은 정부 기관이 최상의 AI 솔루션을 사용할 수 있도록 공급업체 시장에서  강력한 경쟁을 보장할 것을 요구   ∙계약 요건 수립 시 공급업체 의존성을 최소화할 수 있는 인수 원칙을 적용하고, 시장 조사와 요구사항  개발, 공급업체 평가 절차에서 상호운용성과 투명성을 고려하며, 혁신적 조달 관행을 활용해 우수한  계약업체 성과와 정부 기관의 임무 성과를 보장 n (연방정부 전반의 협업 보장) 빠르게 발전하는 AI 기술환경의 위험관리를 위해 AI 전문지식을 갖춘  공무원과 조달, 개인정보보호, 사이버보안 전문가를 포함하는 협업 팀을 구성해 전략적 조달을 지원   ∙각 정부 기관은 기관 간 협의회를 구성해 효과적이고 책임 있는 AI 조달을 지원하고, 협업 시 기관 목표에  가장 적합한 AI 투자 식별 및 우선순위 지정, AI 배포 역량 개발, AI 모범 활용 사례 채택 증진 등을 고려 ☞ 출처: The White House, FACT SHEET: OMB Issues Guidance to Advance the Responsible Acquisition of AI in  Government, 2024.10.03.'\n"
     ]
    }
   ],
   "source": [
    "# CharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# 텍스트를 두 줄바꿈(\"\\n\\n\")을 기준으로 분할, 최대 500자, 50자 겹침, 정규식 아닌 일반 문자열로 처리\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",  # 텍스트를 두 줄바꿈 기준으로 분할\n",
    "    chunk_size=500,    # 각 덩어리의 최대 크기 500자\n",
    "    chunk_overlap=50,  # 각 덩어리 간 50자 겹침\n",
    "    length_function=len,  # 텍스트 길이 계산에 `len()` 사용\n",
    "    is_separator_regex=False  # separator는 정규식이 아닌 일반 문자열로 처리\n",
    ")\n",
    "\n",
    "splits_CTS = text_splitter.split_documents(pages)\n",
    "\n",
    "# Document 객체의 page_content 속성에서 텍스트의 길이를 측정\n",
    "char_list = []\n",
    "for i in range(len(splits_CTS)):\n",
    "    char_list.append(len(splits_CTS[i].page_content))\n",
    "print(\"chunk_size:\")\n",
    "print(char_list[:20])\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 상위 50개 청크 선택\n",
    "top_50_chunks_CTS = splits_CTS[:5]  # 순차적으로 상위 50개 청크 선택(제출용 5개)\n",
    "\n",
    "# 상위 50개 청크 출력\n",
    "for i, chunk in enumerate(top_50_chunks_CTS):\n",
    "    print(f\"Chunk {i + 1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2becd546-eecc-45bf-9229-76e57b270611",
   "metadata": {},
   "source": [
    "#### CharacterTextSplitter(비추천)\n",
    "\n",
    "`CharacterTextSplitter`는 단일 구분자를 기준으로 텍스트를 분리합니다. 주로 하나의 특정 구분자(예: 공백, 구두점 등)를 사용하여 텍스트를 여러 조각으로 나누는 방식입니다. 이 방법은 텍스트가 일정한 패턴이나 규칙을 따를 때 유용하지만, 텍스트의 길이가 너무 길어져서 모델의 최대 토큰 수(맥스 토큰)를 초과할 수 있습니다. 이 경우, 텍스트를 분할할 때 자연스럽지 않거나 부자연스러운 지점에서 끊어질 수 있어, 전체적인 의미나 흐름이 손상될 위험이 존재합니다.\n",
    "\n",
    "따라서, `CharacterTextSplitter`는 맥스 토큰 수를 유지하려는 목적에서는 일부 한계를 가질 수 있으며, 긴 텍스트를 처리할 때는 그 자체로 문제가 발생할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9616a854-9c3a-42eb-9128-e0efe69b6857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_size:\n",
      "[10, 499, 497, 181, 17, 497, 496, 499, 188, 497, 498, 499, 214, 498, 495, 497, 201, 500, 496, 498]\n",
      "====================================================================================================\n",
      "Chunk 1: page_content='2024년 11월호'\n",
      "Chunk 2: page_content='2024년 11월호 Ⅰ. 인공지능 산업 동향 브리프  1. 정책/법제     ▹ 미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석 1    ▹ 미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표 2    ▹ 유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간 3    ▹ OECD, 공공 부문의 AI 도입을 위한 G7 툴킷 발표 4    ▹ 세계경제포럼, 생성AI 시대의 거버넌스 프레임워크 제시 5    2. 기업/산업     ▹ CB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중 6    ▹ 메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개 7    ▹ 메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개 8    ▹ 앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개 9    ▹ 미스트랄AI, 온디바이스용 AI 모델 ‘레 미니스트로’'\n",
      "Chunk 3: page_content='LLM ‘몰모’ 공개 9    ▹ 미스트랄AI, 온디바이스용 AI 모델 ‘레 미니스트로’ 공개 10    ▹ 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개 11  3. 기술/연구    ▹ 2024년 노벨 물리학상과 화학상, AI 관련 연구자들이 수상 12    ▹ 미국 국무부, AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표 13    ▹ 일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간 14    ▹ 구글 딥마인드, 반도체 칩 레이아웃 설계하는 AI 모델 ‘알파칩’ 발표 15    ▹ AI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조 16      4. 인력/교육         ▹ MIT 산업성과센터, 근로자 관점에서 자동화 기술의 영향 조사 17    ▹ 다이스 조사, AI 전문가의 73%는 2025년 중 이직 고려 18    ▹ 가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요  19'\n",
      "Chunk 4: page_content='▹ 가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요  19    ▹ 인디드 조사 결과, 생성AI가 인간 근로자 대체할 가능성은 희박 20      Ⅱ. 주요 행사   ▹NeurIPS 2024  21   ▹GenAI Summit Maroc 2024  21   ▹AI Summit Seoul 2024  21'\n",
      "Chunk 5: page_content='Ⅰ. 인공지능 산업 동향 브리프'\n"
     ]
    }
   ],
   "source": [
    "# RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits_RCTS = recursive_text_splitter.split_documents(pages)\n",
    "\n",
    "# Document 객체의 page_content 속성에서 텍스트의 길이를 측정\n",
    "char_list = []\n",
    "for i in range(len(splits_RCTS)):\n",
    "    char_list.append(len(splits_RCTS[i].page_content))\n",
    "print(\"chunk_size:\")\n",
    "print(char_list[:20])\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 상위 50개 청크 선택\n",
    "top_50_chunks_RCTS = splits_RCTS[:5]  # 순차적으로 상위 50개 청크 선택(제출용 5개)\n",
    "\n",
    "# 상위 50개 청크 출력\n",
    "for i, chunk in enumerate(top_50_chunks_RCTS):\n",
    "    print(f\"Chunk {i + 1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aac0cd-914a-4059-aded-cbb14263d1ab",
   "metadata": {},
   "source": [
    "#### RecursiveCharacterTextSplitter(추천)\n",
    "\n",
    "`RecursiveCharacterTextSplitter`는 여러 구분자를 사용하여 텍스트를 재귀적으로 나누는 방법입니다. 이 방식은 하나의 구분자로 텍스트를 나눈 뒤, 그 결과물에서 또 다른 구분자를 사용해 분할을 반복하는 방식입니다. 이 과정을 통해 더 적절한 지점에서 텍스트를 나누어, 최대 토큰 수를 초과하거나 부족한 상황에 맞게 텍스트의 길이를 동적으로 조절할 수 있습니다.\n",
    "\n",
    "주요 특징은 **맥스 토큰**을 초과할 경우 다른 구분자를 찾아서 분할하고, 반대로 토큰 수가 부족할 경우 자연스럽게 텍스트의 길이를 재조정할 수 있다는 점입니다. 이 과정은 구분자를 재귀적으로 탐색하여 길이를 맞추기 때문에 더 유연하고 효율적으로 텍스트를 다룰 수 있습니다.\n",
    "\n",
    "따라서, `RecursiveCharacterTextSplitter`는 텍스트의 의미를 최대한 유지하면서도 효율적으로 토큰 길이를 조정할 수 있어, **대규모 텍스트 처리**에서 훨씬 더 안정적이고 신뢰할 수 있는 분할 방법이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9644d6b-5de8-46cd-b2be-53779929dc6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count (for each chunk):\n",
      "[9, 472, 462, 20, 23, 497, 497, 500, 497, 499, 383, 497, 496, 384, 481, 499, 352, 495, 499, 437]\n",
      "====================================================================================================\n",
      "Chunk 1: page_content='2024년 11월호'\n",
      "Chunk 2: page_content='2024년 11월호 Ⅰ. 인공지능 산업 동향 브리프  1. 정책/법제     ▹ 미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석 1    ▹ 미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표 2    ▹ 유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간 3    ▹ OECD, 공공 부문의 AI 도입을 위한 G7 툴킷 발표 4    ▹ 세계경제포럼, 생성AI 시대의 거버넌스 프레임워크 제시 5    2. 기업/산업     ▹ CB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중 6    ▹ 메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개 7    ▹ 메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개 8    ▹ 앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개 9    ▹ 미스트랄AI, 온디바이스용 AI 모델 ‘레'\n",
      "Chunk 3: page_content='미니스트로’ 공개 10    ▹ 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개 11  3. 기술/연구    ▹ 2024년 노벨 물리학상과 화학상, AI 관련 연구자들이 수상 12    ▹ 미국 국무부, AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표 13    ▹ 일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간 14    ▹ 구글 딥마인드, 반도체 칩 레이아웃 설계하는 AI 모델 ‘알파칩’ 발표 15    ▹ AI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조 16      4. 인력/교육         ▹ MIT 산업성과센터, 근로자 관점에서 자동화 기술의 영향 조사 17    ▹ 다이스 조사, AI 전문가의 73%는 2025년 중 이직 고려 18    ▹ 가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요  19    ▹ 인디드 조사 결과, 생성AI가 인간 근로자 대체할 가능성은 희박 20      Ⅱ. 주요 행사   ▹NeurIPS 2024  21   ▹GenAI Summit'\n",
      "Chunk 4: page_content='Maroc 2024  21   ▹AI Summit Seoul 2024  21'\n",
      "Chunk 5: page_content='Ⅰ. 인공지능 산업 동향 브리프'\n"
     ]
    }
   ],
   "source": [
    "# tiktoken 라이브러리와 langchain의 RecursiveCharacterTextSplitter 임포트\n",
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 'cl100k_base' 토크나이저를 가져옴 (OpenAI GPT 모델용)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# tiktoken을 사용하여 텍스트의 토큰 길이를 계산하는 함수 정의\n",
    "def tiktoken_len(text):\n",
    "    # 입력된 텍스트를 'cl100k_base' 토크나이저로 인코딩하여 토큰으로 변환\n",
    "    tokens = tokenizer.encode(text)\n",
    "    # 토큰의 개수를 반환\n",
    "    return len(tokens)\n",
    "\n",
    "# 텍스트 분할기 설정\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0, length_function = tiktoken_len)\n",
    "# 페이지를 500자씩 분할하고, 중복되는 텍스트가 없도록 설정\n",
    "splits_RCTS_tiktoken = recursive_text_splitter.split_documents(pages)  # 분할된 텍스트를 docs 변수에 저장\n",
    "\n",
    "# Document 객체의 page_content 속성에서 텍스트의 길이를 측정\n",
    "token_list = []  # 토큰 수를 저장할 리스트\n",
    "for i in range(len(splits_RCTS_tiktoken)):\n",
    "    token_list.append(tiktoken_len(splits_RCTS_tiktoken[i].page_content))  # page_content에 대해 토큰 수 계산\n",
    "\n",
    "print(\"Token Count (for each chunk):\")\n",
    "print(token_list[:20])  # 처음 20개 토큰 수 출력\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 상위 50개 청크 선택\n",
    "top_50_splits_RCTS_tiktoken = splits_RCTS_tiktoken[:5]  # 순차적으로 상위 50개 청크 선택(제출용 5개)\n",
    "\n",
    "# 상위 50개 청크 출력\n",
    "for i, chunk in enumerate(top_50_splits_RCTS_tiktoken):\n",
    "    print(f\"Chunk {i + 1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73555c26-3137-48cf-af33-989aafe41e1a",
   "metadata": {},
   "source": [
    "#### RecursiveCharacterTextSplitter + 'cl100k_base' tokenizer (OpenAI 최적화)\n",
    "\n",
    "length_function는 텍스트의 길이를 계산하는 함수입니다. tiktoken_len 함수는 tiktoken을 사용하여 토큰의 개수를 기반으로 길이를 계산합니다.\n",
    "\n",
    "이 방식의 중요한 특징은, 텍스트의 의미를 유지하면서도 효율적으로 토큰 수를 조정할 수 있다는 점입니다. 예를 들어, 각 문서나 텍스트가 일정한 크기(토큰 수)에 맞게 나눠져야 하는데, 이때 RecursiveCharacterTextSplitter는 의미 단위에서 자연스럽게 분할점을 찾을 수 있게 도와줍니다. 대규모 데이터나 문서에서 토큰 길이를 최적화하며 분할할 때 유용합니다. 예를 들어, GPT 모델의 입력 제한을 고려하면서 텍스트를 의미 있게 분할할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608f9da7-04fb-44cc-8a64-1c61701bd106",
   "metadata": {},
   "source": [
    "### 04_Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fb7dc08-f549-40d1-aaea-cdc682845e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\241011\\miniconda3\\envs\\p310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1: [0.007192553021013737, 0.04766311123967171, 0.03824799507856369, -0.042096156626939774, -0.05990616977214813, 0.04244782775640488, -0.024665698409080505, 0.04018503427505493, -0.011240575462579727, 0.0046769361943006516]...\n",
      "Embedding 2: [0.01452606450766325, 0.03009106032550335, 0.018209030851721764, 0.025725917890667915, 0.03480705991387367, -0.004691502079367638, -0.010673526674509048, 0.03857724368572235, -0.017304139211773872, 0.014899186789989471]...\n",
      "Embedding 3: [0.003480087034404278, 0.011522029526531696, 0.041415080428123474, 0.03863849118351936, 0.033902231603860855, 0.00990673340857029, 0.03298669680953026, 0.07887616008520126, -0.03317802771925926, 0.002298360923305154]...\n",
      "Embedding 4: [0.004809824284166098, -0.0035063030663877726, 0.02380705624818802, -0.02391723543405533, -0.026917850598692894, 0.03532356396317482, 0.06605891138315201, -0.0015997928567230701, -0.0058829160407185555, 0.023183612152934074]...\n",
      "Embedding 5: [0.038928281515836716, -0.04519323259592056, 0.0600542314350605, 0.06341224163770676, 0.05292894318699837, -0.036623112857341766, -0.040713973343372345, 0.04780227318406105, -0.028642725199460983, 0.007615695707499981]...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# HuggingFace 모델 캐시 경로 설정 (로컬에 저장)\n",
    "#os.environ[\"TRANSFORMERS_CACHE\"] = r\"C:\\Users\\241011\\Documents\\models\"\n",
    "os.environ[\"HF_HOME\"] = r\"C:\\Users\\241011\\Documents\\models\"\n",
    "\n",
    "# 모델 이름 및 설정\n",
    "model_name = \"jhgan/ko-sbert-nli\"  # 한국어 임베딩 모델\n",
    "#model_kwargs = {'device': 'cpu'}  # CPU에서 모델을 실행\n",
    "model_kwargs = {'device': 'cuda'}  # GPU에서 모델을 실행\n",
    "encode_kwargs = {'normalize_embeddings': True}  # 임베딩 정규화\n",
    "\n",
    "# HuggingFace 임베딩 객체 생성\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# 각 분할된 텍스트에 대해 임베딩 생성\n",
    "doc_list = [split.page_content for split in splits_RCTS_tiktoken]  # 텍스트만 추출\n",
    "embeddings_list = embeddings.embed_documents(doc_list)\n",
    "\n",
    "\n",
    "# 임베딩 결과 출력 (예시)\n",
    "for idx, embedding in enumerate(embeddings_list[:5]):  # 첫 5개만 출력 예시\n",
    "    print(f\"Embedding {idx + 1}: {embedding[:10]}...\")  # 임베딩의 앞부분만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb03fb13-a2c9-41b4-ad2c-c26f886485c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1: [0.04651528596878052, 0.01456959918141365, -0.06319913268089294, -0.011899527162313461, 0.06261497735977173, 0.009657339192926884, 0.003752728458493948, -0.04713655263185501, 0.02315351739525795, 0.030447103083133698]...\n",
      "Embedding 2: [0.04549642279744148, -0.01782253012061119, -0.030756212770938873, 0.0023554980289191008, 0.08271798491477966, -0.00690112030133605, 0.013421833515167236, -0.023043103516101837, 0.020502565428614616, 0.015528258867561817]...\n",
      "Embedding 3: [0.039247237145900726, 0.007577680982649326, -0.01101694256067276, 0.010201932862401009, 0.07109744101762772, 0.006572442129254341, 0.00017715911963023245, -0.029157651588320732, 0.0264409389346838, 0.02526436373591423]...\n",
      "Embedding 4: [0.04280923306941986, -0.007026223931461573, -0.05925736576318741, -0.02322331629693508, 0.06605707854032516, 0.038070812821388245, 0.006067764014005661, -0.021480754017829895, 0.015613703057169914, 0.061877209693193436]...\n",
      "Embedding 5: [0.03569802641868591, 0.0025280655827373266, -0.055229511111974716, -0.0021386423613876104, 0.07422488927841187, 0.027577580884099007, 0.01204733457416296, -0.039877574890851974, 0.0030086988117545843, 0.04578442499041557]...\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # gemini의 임베딩 모델\n",
    "# 각 분할된 텍스트에 대해 임베딩 생성\n",
    "doc_list = [split.page_content for split in splits_RCTS_tiktoken]  # 텍스트만 추출\n",
    "embeddings_list = embeddings.embed_documents(doc_list)\n",
    "\n",
    "\n",
    "# 임베딩 결과 출력 (예시)\n",
    "for idx, embedding in enumerate(embeddings_list[:5]):  # 첫 5개만 출력 예시\n",
    "    print(f\"Embedding {idx + 1}: {embedding[:10]}...\")  # 임베딩의 앞부분만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31800f0d-d6ea-4270-a4a7-0416ca4d5a08",
   "metadata": {},
   "source": [
    "### 05_Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54195391-4ffc-46ae-a557-2a75a8b3a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "kn = 3\n",
    "\n",
    "# FAISS VectorStore 생성\n",
    "faiss_vectorstore = FAISS.from_documents(documents=splits_RCTS_tiktoken, embedding=embeddings)\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Chroma 설정\n",
    "client = chromadb.Client()\n",
    "chroma_vectorstore = Chroma.from_documents(documents=splits_RCTS_tiktoken, embedding=embeddings, client=client)\n",
    "chroma_retriever = chroma_vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# BM25 retriever 생성\n",
    "bm25_retriever = BM25Retriever.from_texts(doc_list)\n",
    "bm25_retriever.k = 3\n",
    "\n",
    "# EnsembleRetriever 생성 (FAISS, Chroma, 결과 결합)\n",
    "ensemble_01_retriever = EnsembleRetriever(\n",
    "    retrievers=[faiss_retriever, chroma_retriever],\n",
    "    weight=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# EnsembleRetriever 생성 (FAISS, BM25 결과 결합)\n",
    "ensemble_02_retriever = EnsembleRetriever(\n",
    "    retrievers=[faiss_retriever, bm25_retriever],\n",
    "    weight=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# EnsembleRetriever 생성 (Chroma, BM25 결과 결합)\n",
    "ensemble_03_retriever = EnsembleRetriever(\n",
    "    retrievers=[chroma_retriever, bm25_retriever],\n",
    "    weight=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# EnsembleRetriever 생성 (Chroma, FAISS, BM25 결과 결합)\n",
    "ensemble_04_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, chroma_retriever, faiss_retriever],\n",
    "    weight=[0.33, 0.33, 0.33]  # 세 가지 retriever의 결과를 동일한 비율로 결합\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6517abf-5fb7-46d3-9b74-3f193d50c9d4",
   "metadata": {},
   "source": [
    "### 05_01_Vectorstores_Output(생략)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0a728fe-0433-4b09-b548-a52b4fdd36d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FAISS Retriever]\n",
      "Content: 1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 11 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개 n 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI  메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정 n 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발  중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획  KEY Contents £ 카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현  n 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의  AI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표 ∙사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지  않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의\n",
      "\n",
      "Content: 해결 역량  △기술 활용 시 물리적 작업의 중요성에 관한 판단 능력의 3개 차원에서 자체 수행 능력을 평가하도록 진행  ∙다섯 가지 선택지(매우 낮음, 낮음, 보통, 높음, 매우 높음)로 평가 결과, 인디드가 평가 대상으로 삼은  2,800개 이상의 직무 기술 중 68.7%는 생성AI로 대체될 가능성이 “매우 낮음” 또는 “낮음”으로  평가됐으며, “매우 높음”으로 평가된 기술은 전무 n 생성AI는 직무 기술의 이론적 지식을 제공하는 자체 능력을 다소 높게 평가했으나, 문제 해결  능력 및 물리적 작업의 중요성에 관한 판단 능력은 상대적으로 낮게 평가 ∙생성AI는 직무 기술 중 79.7%에 이론적 지식의 제공 능력을 4점(높음)으로, 기술 중 70.7%에 문제  해결 역량을 3점(보통)으로 평가했으며, 기술 중 54%에 대하여 물리적 작업의 필요성이 “높음” 또는  “매우 높음”이라고 평가* * 매우 낮음(very unlikely 1점), 낮음(unlikely, 2점), 보통(possible, 3점), 높음(likely, 4점), 매우 높음(very likely,\n",
      "\n",
      "Content: 규제를 활용하고 생성AI로 인한 규제 격차를 해소하는 것으로, 정부는 새로운 AI  규제나 관할 당국을 수립하기에 앞서 다음 사항을 추진할 필요 ∙생성AI로 인한 문제나 격차 발생에 관하여 기존 규제를 평가하고 다양한 규제 수단의 정책 목표를  고려해 규제를 조정하며, 규제 선례를 참고해 책임 할당을 명확히 하고 격차가 발견된 부분을 보완 ∙기존 규제 당국이 생성AI 문제를 해결할 역량이 있는지 평가하고, AI 전담 기관을 설치하여 규제  권한을 집중하는 방안의 장단점을 고려 n (현재 구축) 사회 전반의 생성AI 거버넌스와 지식 공유의 증진을 의미하며, 생성AI의 거버넌스에는  정책입안자와 규제 당국 외에 산업계, 시민사회, 학계를 포함한 이해관계자 참여가 필수적 ∙정부는 다양한 거버넌스 수단을 활용해 사회 전반의 생성AI 거버넌스에 참여하는 각 이해관계자  집단의 고유한 문제에 대응 필요 ∙다양한 이해관계자 간 지식 공유를 촉진하고, 책임 있는 AI 관행으로 사회에 모범을 보일 필요성 존재 n (미래\n",
      "\n",
      "[chroma_retriever]\n",
      "Content: 1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 11 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개 n 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI  메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정 n 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발  중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획  KEY Contents £ 카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현  n 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의  AI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표 ∙사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지  않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의\n",
      "\n",
      "Content: 1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 11 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개 n 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI  메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정 n 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발  중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획  KEY Contents £ 카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현  n 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의  AI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표 ∙사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지  않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의\n",
      "\n",
      "Content: 1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 11 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개 n 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI  메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정 n 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발  중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획  KEY Contents £ 카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현  n 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의  AI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표 ∙사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지  않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의\n",
      "\n",
      "[BM25 Retriever]\n",
      "Content: Ⅰ. 인공지능 산업 동향 브리프\n",
      "\n",
      "Content: 1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 7 메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개 n 메타가 동영상 생성, 개인화 동영상 제작, 동영상 편집, 오디오 생성과 같은 기능을 지원하는  ‘메타 무비 젠’을 공개하고 2025년 중 인스타그램 등 자사 플랫폼에 통합할 계획 n 메타 무비 젠은 인간 선호도 평가에서 런웨이의 젠 3, 오픈AI의 소라, 클링 1.5와 같은 경쟁  동영상 AI 모델보다 더 높은 점수를 기록 KEY Contents £ 메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개  n 메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타  무비 젠(Meta Movie Gen)’을 공개 ∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을  반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과  같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침 n\n",
      "\n",
      "Content: 메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원 ∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대  16초 길이 동영상 생성을 지원 ∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을  반영한 개인화 동영상을 제작 가능 ∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과  같은 광범위한 수정도 지원 ∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로  최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성 £ 메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가 n 메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를  비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록 ∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간\n",
      "\n",
      "[FAISS, Chroma Ensemble Retriever]\n",
      "Content: 1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 11 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개 n 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI  메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정 n 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발  중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획  KEY Contents £ 카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현  n 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의  AI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표 ∙사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지  않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의\n",
      "\n",
      "Content: 해결 역량  △기술 활용 시 물리적 작업의 중요성에 관한 판단 능력의 3개 차원에서 자체 수행 능력을 평가하도록 진행  ∙다섯 가지 선택지(매우 낮음, 낮음, 보통, 높음, 매우 높음)로 평가 결과, 인디드가 평가 대상으로 삼은  2,800개 이상의 직무 기술 중 68.7%는 생성AI로 대체될 가능성이 “매우 낮음” 또는 “낮음”으로  평가됐으며, “매우 높음”으로 평가된 기술은 전무 n 생성AI는 직무 기술의 이론적 지식을 제공하는 자체 능력을 다소 높게 평가했으나, 문제 해결  능력 및 물리적 작업의 중요성에 관한 판단 능력은 상대적으로 낮게 평가 ∙생성AI는 직무 기술 중 79.7%에 이론적 지식의 제공 능력을 4점(높음)으로, 기술 중 70.7%에 문제  해결 역량을 3점(보통)으로 평가했으며, 기술 중 54%에 대하여 물리적 작업의 필요성이 “높음” 또는  “매우 높음”이라고 평가* * 매우 낮음(very unlikely 1점), 낮음(unlikely, 2점), 보통(possible, 3점), 높음(likely, 4점), 매우 높음(very likely,\n",
      "\n",
      "Content: 규제를 활용하고 생성AI로 인한 규제 격차를 해소하는 것으로, 정부는 새로운 AI  규제나 관할 당국을 수립하기에 앞서 다음 사항을 추진할 필요 ∙생성AI로 인한 문제나 격차 발생에 관하여 기존 규제를 평가하고 다양한 규제 수단의 정책 목표를  고려해 규제를 조정하며, 규제 선례를 참고해 책임 할당을 명확히 하고 격차가 발견된 부분을 보완 ∙기존 규제 당국이 생성AI 문제를 해결할 역량이 있는지 평가하고, AI 전담 기관을 설치하여 규제  권한을 집중하는 방안의 장단점을 고려 n (현재 구축) 사회 전반의 생성AI 거버넌스와 지식 공유의 증진을 의미하며, 생성AI의 거버넌스에는  정책입안자와 규제 당국 외에 산업계, 시민사회, 학계를 포함한 이해관계자 참여가 필수적 ∙정부는 다양한 거버넌스 수단을 활용해 사회 전반의 생성AI 거버넌스에 참여하는 각 이해관계자  집단의 고유한 문제에 대응 필요 ∙다양한 이해관계자 간 지식 공유를 촉진하고, 책임 있는 AI 관행으로 사회에 모범을 보일 필요성 존재 n (미래\n",
      "\n",
      "[FAISS, BM25 Ensemble Retriever]\n",
      "Content: 1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 11 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개 n 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI  메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정 n 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발  중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획  KEY Contents £ 카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현  n 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의  AI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표 ∙사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지  않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의\n",
      "\n",
      "Content: Ⅰ. 인공지능 산업 동향 브리프\n",
      "\n",
      "Content: 해결 역량  △기술 활용 시 물리적 작업의 중요성에 관한 판단 능력의 3개 차원에서 자체 수행 능력을 평가하도록 진행  ∙다섯 가지 선택지(매우 낮음, 낮음, 보통, 높음, 매우 높음)로 평가 결과, 인디드가 평가 대상으로 삼은  2,800개 이상의 직무 기술 중 68.7%는 생성AI로 대체될 가능성이 “매우 낮음” 또는 “낮음”으로  평가됐으며, “매우 높음”으로 평가된 기술은 전무 n 생성AI는 직무 기술의 이론적 지식을 제공하는 자체 능력을 다소 높게 평가했으나, 문제 해결  능력 및 물리적 작업의 중요성에 관한 판단 능력은 상대적으로 낮게 평가 ∙생성AI는 직무 기술 중 79.7%에 이론적 지식의 제공 능력을 4점(높음)으로, 기술 중 70.7%에 문제  해결 역량을 3점(보통)으로 평가했으며, 기술 중 54%에 대하여 물리적 작업의 필요성이 “높음” 또는  “매우 높음”이라고 평가* * 매우 낮음(very unlikely 1점), 낮음(unlikely, 2점), 보통(possible, 3점), 높음(likely, 4점), 매우 높음(very likely,\n",
      "\n",
      "Content: 1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 7 메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개 n 메타가 동영상 생성, 개인화 동영상 제작, 동영상 편집, 오디오 생성과 같은 기능을 지원하는  ‘메타 무비 젠’을 공개하고 2025년 중 인스타그램 등 자사 플랫폼에 통합할 계획 n 메타 무비 젠은 인간 선호도 평가에서 런웨이의 젠 3, 오픈AI의 소라, 클링 1.5와 같은 경쟁  동영상 AI 모델보다 더 높은 점수를 기록 KEY Contents £ 메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개  n 메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타  무비 젠(Meta Movie Gen)’을 공개 ∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을  반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과  같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침 n\n",
      "\n",
      "Content: 규제를 활용하고 생성AI로 인한 규제 격차를 해소하는 것으로, 정부는 새로운 AI  규제나 관할 당국을 수립하기에 앞서 다음 사항을 추진할 필요 ∙생성AI로 인한 문제나 격차 발생에 관하여 기존 규제를 평가하고 다양한 규제 수단의 정책 목표를  고려해 규제를 조정하며, 규제 선례를 참고해 책임 할당을 명확히 하고 격차가 발견된 부분을 보완 ∙기존 규제 당국이 생성AI 문제를 해결할 역량이 있는지 평가하고, AI 전담 기관을 설치하여 규제  권한을 집중하는 방안의 장단점을 고려 n (현재 구축) 사회 전반의 생성AI 거버넌스와 지식 공유의 증진을 의미하며, 생성AI의 거버넌스에는  정책입안자와 규제 당국 외에 산업계, 시민사회, 학계를 포함한 이해관계자 참여가 필수적 ∙정부는 다양한 거버넌스 수단을 활용해 사회 전반의 생성AI 거버넌스에 참여하는 각 이해관계자  집단의 고유한 문제에 대응 필요 ∙다양한 이해관계자 간 지식 공유를 촉진하고, 책임 있는 AI 관행으로 사회에 모범을 보일 필요성 존재 n (미래\n",
      "\n",
      "Content: 메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원 ∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대  16초 길이 동영상 생성을 지원 ∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을  반영한 개인화 동영상을 제작 가능 ∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과  같은 광범위한 수정도 지원 ∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로  최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성 £ 메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가 n 메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를  비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록 ∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간\n",
      "\n",
      "[Chroma, BM25 Ensemble Retriever]\n",
      "Content: 1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 11 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개 n 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI  메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정 n 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발  중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획  KEY Contents £ 카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현  n 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의  AI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표 ∙사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지  않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의\n",
      "\n",
      "Content: Ⅰ. 인공지능 산업 동향 브리프\n",
      "\n",
      "Content: 1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 7 메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개 n 메타가 동영상 생성, 개인화 동영상 제작, 동영상 편집, 오디오 생성과 같은 기능을 지원하는  ‘메타 무비 젠’을 공개하고 2025년 중 인스타그램 등 자사 플랫폼에 통합할 계획 n 메타 무비 젠은 인간 선호도 평가에서 런웨이의 젠 3, 오픈AI의 소라, 클링 1.5와 같은 경쟁  동영상 AI 모델보다 더 높은 점수를 기록 KEY Contents £ 메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개  n 메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타  무비 젠(Meta Movie Gen)’을 공개 ∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을  반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과  같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침 n\n",
      "\n",
      "Content: 메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원 ∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대  16초 길이 동영상 생성을 지원 ∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을  반영한 개인화 동영상을 제작 가능 ∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과  같은 광범위한 수정도 지원 ∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로  최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성 £ 메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가 n 메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를  비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록 ∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간\n",
      "\n",
      "[Chroma, FAISS, BM25 Ensemble Retriever]\n",
      "Content: 1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 11 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개 n 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI  메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정 n 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발  중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획  KEY Contents £ 카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현  n 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의  AI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표 ∙사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지  않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의\n",
      "\n",
      "Content: Ⅰ. 인공지능 산업 동향 브리프\n",
      "\n",
      "Content: 1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 7 메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개 n 메타가 동영상 생성, 개인화 동영상 제작, 동영상 편집, 오디오 생성과 같은 기능을 지원하는  ‘메타 무비 젠’을 공개하고 2025년 중 인스타그램 등 자사 플랫폼에 통합할 계획 n 메타 무비 젠은 인간 선호도 평가에서 런웨이의 젠 3, 오픈AI의 소라, 클링 1.5와 같은 경쟁  동영상 AI 모델보다 더 높은 점수를 기록 KEY Contents £ 메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개  n 메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타  무비 젠(Meta Movie Gen)’을 공개 ∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을  반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과  같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침 n\n",
      "\n",
      "Content: 해결 역량  △기술 활용 시 물리적 작업의 중요성에 관한 판단 능력의 3개 차원에서 자체 수행 능력을 평가하도록 진행  ∙다섯 가지 선택지(매우 낮음, 낮음, 보통, 높음, 매우 높음)로 평가 결과, 인디드가 평가 대상으로 삼은  2,800개 이상의 직무 기술 중 68.7%는 생성AI로 대체될 가능성이 “매우 낮음” 또는 “낮음”으로  평가됐으며, “매우 높음”으로 평가된 기술은 전무 n 생성AI는 직무 기술의 이론적 지식을 제공하는 자체 능력을 다소 높게 평가했으나, 문제 해결  능력 및 물리적 작업의 중요성에 관한 판단 능력은 상대적으로 낮게 평가 ∙생성AI는 직무 기술 중 79.7%에 이론적 지식의 제공 능력을 4점(높음)으로, 기술 중 70.7%에 문제  해결 역량을 3점(보통)으로 평가했으며, 기술 중 54%에 대하여 물리적 작업의 필요성이 “높음” 또는  “매우 높음”이라고 평가* * 매우 낮음(very unlikely 1점), 낮음(unlikely, 2점), 보통(possible, 3점), 높음(likely, 4점), 매우 높음(very likely,\n",
      "\n",
      "Content: 메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원 ∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대  16초 길이 동영상 생성을 지원 ∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을  반영한 개인화 동영상을 제작 가능 ∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과  같은 광범위한 수정도 지원 ∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로  최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성 £ 메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가 n 메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를  비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록 ∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간\n",
      "\n",
      "Content: 규제를 활용하고 생성AI로 인한 규제 격차를 해소하는 것으로, 정부는 새로운 AI  규제나 관할 당국을 수립하기에 앞서 다음 사항을 추진할 필요 ∙생성AI로 인한 문제나 격차 발생에 관하여 기존 규제를 평가하고 다양한 규제 수단의 정책 목표를  고려해 규제를 조정하며, 규제 선례를 참고해 책임 할당을 명확히 하고 격차가 발견된 부분을 보완 ∙기존 규제 당국이 생성AI 문제를 해결할 역량이 있는지 평가하고, AI 전담 기관을 설치하여 규제  권한을 집중하는 방안의 장단점을 고려 n (현재 구축) 사회 전반의 생성AI 거버넌스와 지식 공유의 증진을 의미하며, 생성AI의 거버넌스에는  정책입안자와 규제 당국 외에 산업계, 시민사회, 학계를 포함한 이해관계자 참여가 필수적 ∙정부는 다양한 거버넌스 수단을 활용해 사회 전반의 생성AI 거버넌스에 참여하는 각 이해관계자  집단의 고유한 문제에 대응 필요 ∙다양한 이해관계자 간 지식 공유를 촉진하고, 책임 있는 AI 관행으로 사회에 모범을 보일 필요성 존재 n (미래\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 검색 결과 문서를 가져옵니다.\n",
    "query = \"메타 인공지능\"\n",
    "\n",
    "faiss_result = faiss_retriever.invoke(query)\n",
    "chroma_result = chroma_retriever.invoke(query)\n",
    "bm25_result = bm25_retriever.invoke(query)\n",
    "ensemble_01_result = ensemble_01_retriever.invoke(query)\n",
    "ensemble_02_result = ensemble_02_retriever.invoke(query)\n",
    "ensemble_03_result = ensemble_03_retriever.invoke(query)\n",
    "ensemble_04_result = ensemble_04_retriever.invoke(query)\n",
    "\n",
    "print(\"[FAISS Retriever]\")\n",
    "for doc in faiss_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "print(\"[chroma_retriever]\")\n",
    "for doc in chroma_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "print(\"[BM25 Retriever]\")\n",
    "for doc in bm25_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "# 가져온 문서를 출력합니다.\n",
    "print(\"[FAISS, Chroma Ensemble Retriever]\")\n",
    "for doc in ensemble_01_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "print(\"[FAISS, BM25 Ensemble Retriever]\")\n",
    "for doc in ensemble_02_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "print(\"[Chroma, BM25 Ensemble Retriever]\")\n",
    "for doc in ensemble_03_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "print(\"[Chroma, FAISS, BM25 Ensemble Retriever]\")\n",
    "for doc in ensemble_04_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba2fe4-3e41-49d6-b734-7b4217f8ca2d",
   "metadata": {},
   "source": [
    "#### 단독\n",
    "\n",
    "**FAISS** : 문서의 임베딩 벡터를 사용하여 의미적 유사성을 기반으로 검색합니다. 즉, 문서의 의미와 관련된 유사한 벡터를 찾아냅니다. FAISS는 대규모 데이터셋에서 고속으로 검색할 수 있는 효율적인 방법입니다.\n",
    "\n",
    "**Chroma**: 벡터 기반의 의미적 유사성 검색을 수행하게 됩니다. Chroma는 임베딩 벡터를 사용하여 문서 간의 의미적 유사성을 계산하고, 쿼리와 가장 유사한 문서를 찾아 반환합니다.\n",
    "\n",
    "**BM25 Retriever** : 주로 정확한 단어 일치를 기반으로 하여, 쿼리와 문서의 키워드 일치 정도에 따라 순위를 매깁니다.\n",
    "\n",
    "#### 앙상블\n",
    "\n",
    "**FAISS + Chroma** : FAISS는 벡터 기반의 의미적 유사성, Chroma는 벡터와 데이터베이스를 사용하여 보다 다양한 의미적 연관성을 찾아냅니다.\n",
    "\n",
    "**FAISS + BM25** : FAISS의 벡터 기반 검색과 BM25의 키워드 기반 검색을 결합하여, 두 방식의 장점을 동시에 취합니다.\n",
    "\n",
    "**Chroma + BM25** : 텍스트의 의미와 키워드를 동시에 고려한 결과를 제공합니다.(**사용**)\n",
    "\n",
    "**FAISS + Chroma + BM25** : FAISS는 의미적 유사성, BM25는 키워드 일치, Chroma는 벡터화된 문서 간 유사성에 기반한 검색을 결합하여, 각 검색 방식이 보완적으로 작용하게 됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14abe089-13ff-4c04-8796-67dd4a1caea5",
   "metadata": {},
   "source": [
    "### 06_LLM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6504218e-0ccc-4836-8106-f05f8992cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c1ea8b-236e-4556-aba2-f0de173695af",
   "metadata": {},
   "source": [
    "### 07_LongContextReorder(미사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8899ab5f-a756-46f9-bb42-e87464cefe64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 11 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개 n 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI  메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정 n 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발  중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획  KEY Contents £ 카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현  n 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의  AI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표 ∙사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지  않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의'),\n",
       " Document(metadata={}, page_content='규제를 활용하고 생성AI로 인한 규제 격차를 해소하는 것으로, 정부는 새로운 AI  규제나 관할 당국을 수립하기에 앞서 다음 사항을 추진할 필요 ∙생성AI로 인한 문제나 격차 발생에 관하여 기존 규제를 평가하고 다양한 규제 수단의 정책 목표를  고려해 규제를 조정하며, 규제 선례를 참고해 책임 할당을 명확히 하고 격차가 발견된 부분을 보완 ∙기존 규제 당국이 생성AI 문제를 해결할 역량이 있는지 평가하고, AI 전담 기관을 설치하여 규제  권한을 집중하는 방안의 장단점을 고려 n (현재 구축) 사회 전반의 생성AI 거버넌스와 지식 공유의 증진을 의미하며, 생성AI의 거버넌스에는  정책입안자와 규제 당국 외에 산업계, 시민사회, 학계를 포함한 이해관계자 참여가 필수적 ∙정부는 다양한 거버넌스 수단을 활용해 사회 전반의 생성AI 거버넌스에 참여하는 각 이해관계자  집단의 고유한 문제에 대응 필요 ∙다양한 이해관계자 간 지식 공유를 촉진하고, 책임 있는 AI 관행으로 사회에 모범을 보일 필요성 존재 n (미래'),\n",
       " Document(metadata={}, page_content='전반의 협업 보장이라는 3개  전략적 목표에 대하여 권고사항을 제시 n (AI 위험과 성과 관리) 예산관리국의 지침은 AI 시스템의 구축, 훈련, 배포 방식의 복잡성을 고려해  AI의 위험과 성과를 관리하기 위한 모범 관행을 다음과 같이 제시 ∙정부 기관의 개인정보 보호 담당자가 AI 조달 프로세스에 조기에 지속적으로 참여해 개인정보 보호  위험을 식별 및 관리하고 법률과 정책 준수를 보장 ∙정부 기관과 공급업체와 간 협력으로 AI 솔루션이 조달되는 시기와 해당 조달로 인해 시민 권리와  안전에 영향을 미치는 AI에 대하여 추가로 위험관리가 필요한 시점을 파악 ∙성과 기반의 혁신적 조달 기법을 활용해 정부 기관이 위험을 효과적으로 관리 및 완화하고 성과를 향상할  수 있도록 장려하는 한편, 정부 데이터와 지식재산권을 보호하는 방식으로 계약 조건을 협상  n (AI 시장의 경쟁 촉진) 지침은 정부 기관이 최상의 AI 솔루션을 사용할 수 있도록 공급업체 시장에서  강력한 경쟁을 보장할 것을 요구   ∙계약 요건 수립 시 공급업체 의존성을 최소화할'),\n",
       " Document(metadata={}, page_content='1. 정책/법제   2. 기업/산업  3. 기술/연구   4. 인력/교육 5 세계경제포럼, 생성AI 시대의 거버넌스 프레임워크 제시 n 세계경제포럼이 글로벌 정책입안자를 대상으로 생성AI의 공익적 활용과 경제사회적  균형 달성, 위험 완화를 위한 거버넌스 프레임워크를 제안하는 백서를 발표 n 백서에 따르면 정부는 기존 규제를 평가해 생성AI로 인한 규제 격차를 해소하는 한편, 다양한  이해관계자 간 지식 공유를 촉진하고 미래의 AI 발전에 대비한 규제 민첩성을 갖출 필요 KEY Contents £ 생성AI 거버넌스, 과거-현재-미래를 아우르는 프레임워크 수립 필요 n 세계경제포럼(WEF)이 2024년 10월 8일 세계 각국의 정책입안자를 대상으로 생성AI 거버넌스  프레임워크를 제시한 백서를 발간 ∙백서는 생성AI의 공익적 활용과 경제사회적 균형 달성, 위험 완화라는 목표 달성을 위해 △과거  활용(Harness Past) △현재 구축(Build Present) △미래 계획(Plan Future)의 프레임워크를 제안 n (과거 활용) 기존'),\n",
       " Document(metadata={}, page_content='해결 역량  △기술 활용 시 물리적 작업의 중요성에 관한 판단 능력의 3개 차원에서 자체 수행 능력을 평가하도록 진행  ∙다섯 가지 선택지(매우 낮음, 낮음, 보통, 높음, 매우 높음)로 평가 결과, 인디드가 평가 대상으로 삼은  2,800개 이상의 직무 기술 중 68.7%는 생성AI로 대체될 가능성이 “매우 낮음” 또는 “낮음”으로  평가됐으며, “매우 높음”으로 평가된 기술은 전무 n 생성AI는 직무 기술의 이론적 지식을 제공하는 자체 능력을 다소 높게 평가했으나, 문제 해결  능력 및 물리적 작업의 중요성에 관한 판단 능력은 상대적으로 낮게 평가 ∙생성AI는 직무 기술 중 79.7%에 이론적 지식의 제공 능력을 4점(높음)으로, 기술 중 70.7%에 문제  해결 역량을 3점(보통)으로 평가했으며, 기술 중 54%에 대하여 물리적 작업의 필요성이 “높음” 또는  “매우 높음”이라고 평가* * 매우 낮음(very unlikely 1점), 낮음(unlikely, 2점), 보통(possible, 3점), 높음(likely, 4점), 매우 높음(very likely,')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_transformers import LongContextReorder \n",
    "reordering = LongContextReorder()\n",
    "reordered_docs = reordering.transform_documents(ensemble_01_result)\n",
    "\n",
    "# Confirm that the 4 relevant documents are at beginning and end.\n",
    "reordered_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee29eee0-cfd2-43e9-9876-5cd0914bbbe9",
   "metadata": {},
   "source": [
    "### 08_RAG+prompt_engineering_load_and_save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d00fc09-e7b2-435d-b450-03929e93c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import LLMChain, StuffDocumentsChain \n",
    "\n",
    "\n",
    "\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the question using only the following context.\"),\n",
    "    (\"user\", \"Context: {context}\\\\n\\\\nQuestion: {query}\")\n",
    "])\n",
    "\n",
    "# 디버그 패스쓰루\n",
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        \n",
    "        # output의 실제 타입 확인\n",
    "        if isinstance(output, dict):\n",
    "            # 문서 내용 출력 (각 문서 구분만 하기)\n",
    "            documents = output.get('context', [])\n",
    "            for idx, doc in enumerate(documents):\n",
    "                # 각 문서의 page_content를 출력\n",
    "                print(f\"Document {idx + 1}:\")\n",
    "                print(doc.page_content)  # Document 객체의 page_content 출력\n",
    "                print(\"========================\")  # 각 문서 구분선\n",
    "        else:\n",
    "            print(output)\n",
    "        return output\n",
    "\n",
    "# 문서 리스트를 텍스트로 변환하는 단계 추가\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):  # config 인수 추가\n",
    "        # context의 각 문서를 문자열로 결합\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        return {\"context\": context_text, \"query\": inputs[\"query\"]}\n",
    "\n",
    "# RAG 체인에서 각 단계마다 DebugPassThrough 추가\n",
    "rag_chain_debug = (\n",
    "    {\"context\": chroma_retriever , \"query\": RunnablePassthrough()}\n",
    "    | DebugPassThrough() \n",
    "    | ContextToText() \n",
    "    | contextual_prompt \n",
    "    | model \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1bec73ed-dbeb-4c47-9525-4d406d8f63d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (803023069.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[68], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"), stream=True])\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_transformers import LongContextReorder \n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"user\", \"\"\"\n",
    "Answer the question as based only on the following context:\\n\n",
    "{context}\\n\\n\n",
    "Question: {question}\n",
    "\"\"\")])\n",
    "\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "callback_handler = StreamingStdOutCallbackHandler()\n",
    "\n",
    "class prompt_debug(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "\n",
    "def format_docs(docs):\n",
    "    print(\"docs:\", docs)\n",
    "    reordering = LongContextReorder()\n",
    "    reordered_docs = reordering.transform_documents(docs)\n",
    "    print(\"reordered_docs:\", reordered_docs)\n",
    "    \n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in reordered_docs )\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": chroma_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | prompt_debug()\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = rag_chain.invoke(\"kakao의 인공지능에 대해 알려줘\")\n",
    "\n",
    "print(result)\n",
    "\n",
    "import time\n",
    "\n",
    "def real_time_print(text, delay=0.1):\n",
    "    \"\"\"\n",
    "    주어진 텍스트를 한자 한자 실시간으로 출력하는 함수.\n",
    "    \n",
    "    :param text: 출력할 텍스트\n",
    "    :param delay: 글자 출력 간의 지연 시간 (초 단위)\n",
    "    \"\"\"\n",
    "    for char in text:\n",
    "        print(char, end='', flush=True)\n",
    "        time.sleep(delay)  # 각 글자 출력 후 지연 시간을 설정\n",
    "    print()  # 마지막에는 줄 바꿈을 추가\n",
    "\n",
    "#real_time_print(result, delay=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43638ef7-4e12-4603-87fb-e1d3b9e291da",
   "metadata": {},
   "source": [
    "### 09_RAG_답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "197b1a9c-d87e-4601-9f37-10ed2e2315ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "규제를 활용하고 생성AI로 인한 규제 격차를 해소하는 것으로, 정부는 새로운 AI  규제나 관할 당국을 수립하기에 앞서 다음 사항을 추진할 필요 ∙생성AI로 인한 문제나 격차 발생에 관하여 기존 규제를 평가하고 다양한 규제 수단의 정책 목표를  고려해 규제를 조정하며, 규제 선례를 참고해 책임 할당을 명확히 하고 격차가 발견된 부분을 보완 ∙기존 규제 당국이 생성AI 문제를 해결할 역량이 있는지 평가하고, AI 전담 기관을 설치하여 규제  권한을 집중하는 방안의 장단점을 고려 n (현재 구축) 사회 전반의 생성AI 거버넌스와 지식 공유의 증진을 의미하며, 생성AI의 거버넌스에는  정책입안자와 규제 당국 외에 산업계, 시민사회, 학계를 포함한 이해관계자 참여가 필수적 ∙정부는 다양한 거버넌스 수단을 활용해 사회 전반의 생성AI 거버넌스에 참여하는 각 이해관계자  집단의 고유한 문제에 대응 필요 ∙다양한 이해관계자 간 지식 공유를 촉진하고, 책임 있는 AI 관행으로 사회에 모범을 보일 필요성 존재 n (미래\n",
      "========================\n",
      "Document 2:\n",
      "규제를 활용하고 생성AI로 인한 규제 격차를 해소하는 것으로, 정부는 새로운 AI  규제나 관할 당국을 수립하기에 앞서 다음 사항을 추진할 필요 ∙생성AI로 인한 문제나 격차 발생에 관하여 기존 규제를 평가하고 다양한 규제 수단의 정책 목표를  고려해 규제를 조정하며, 규제 선례를 참고해 책임 할당을 명확히 하고 격차가 발견된 부분을 보완 ∙기존 규제 당국이 생성AI 문제를 해결할 역량이 있는지 평가하고, AI 전담 기관을 설치하여 규제  권한을 집중하는 방안의 장단점을 고려 n (현재 구축) 사회 전반의 생성AI 거버넌스와 지식 공유의 증진을 의미하며, 생성AI의 거버넌스에는  정책입안자와 규제 당국 외에 산업계, 시민사회, 학계를 포함한 이해관계자 참여가 필수적 ∙정부는 다양한 거버넌스 수단을 활용해 사회 전반의 생성AI 거버넌스에 참여하는 각 이해관계자  집단의 고유한 문제에 대응 필요 ∙다양한 이해관계자 간 지식 공유를 촉진하고, 책임 있는 AI 관행으로 사회에 모범을 보일 필요성 존재 n (미래\n",
      "========================\n",
      "Document 3:\n",
      "전반의 협업 보장이라는 3개  전략적 목표에 대하여 권고사항을 제시 n (AI 위험과 성과 관리) 예산관리국의 지침은 AI 시스템의 구축, 훈련, 배포 방식의 복잡성을 고려해  AI의 위험과 성과를 관리하기 위한 모범 관행을 다음과 같이 제시 ∙정부 기관의 개인정보 보호 담당자가 AI 조달 프로세스에 조기에 지속적으로 참여해 개인정보 보호  위험을 식별 및 관리하고 법률과 정책 준수를 보장 ∙정부 기관과 공급업체와 간 협력으로 AI 솔루션이 조달되는 시기와 해당 조달로 인해 시민 권리와  안전에 영향을 미치는 AI에 대하여 추가로 위험관리가 필요한 시점을 파악 ∙성과 기반의 혁신적 조달 기법을 활용해 정부 기관이 위험을 효과적으로 관리 및 완화하고 성과를 향상할  수 있도록 장려하는 한편, 정부 데이터와 지식재산권을 보호하는 방식으로 계약 조건을 협상  n (AI 시장의 경쟁 촉진) 지침은 정부 기관이 최상의 AI 솔루션을 사용할 수 있도록 공급업체 시장에서  강력한 경쟁을 보장할 것을 요구   ∙계약 요건 수립 시 공급업체 의존성을 최소화할\n",
      "========================\n",
      "Document 4:\n",
      "전반의 협업 보장이라는 3개  전략적 목표에 대하여 권고사항을 제시 n (AI 위험과 성과 관리) 예산관리국의 지침은 AI 시스템의 구축, 훈련, 배포 방식의 복잡성을 고려해  AI의 위험과 성과를 관리하기 위한 모범 관행을 다음과 같이 제시 ∙정부 기관의 개인정보 보호 담당자가 AI 조달 프로세스에 조기에 지속적으로 참여해 개인정보 보호  위험을 식별 및 관리하고 법률과 정책 준수를 보장 ∙정부 기관과 공급업체와 간 협력으로 AI 솔루션이 조달되는 시기와 해당 조달로 인해 시민 권리와  안전에 영향을 미치는 AI에 대하여 추가로 위험관리가 필요한 시점을 파악 ∙성과 기반의 혁신적 조달 기법을 활용해 정부 기관이 위험을 효과적으로 관리 및 완화하고 성과를 향상할  수 있도록 장려하는 한편, 정부 데이터와 지식재산권을 보호하는 방식으로 계약 조건을 협상  n (AI 시장의 경쟁 촉진) 지침은 정부 기관이 최상의 AI 솔루션을 사용할 수 있도록 공급업체 시장에서  강력한 경쟁을 보장할 것을 요구   ∙계약 요건 수립 시 공급업체 의존성을 최소화할\n",
      "========================\n",
      "Document 5:\n",
      "증거 수집, 이미지와 비디오 분석, 생체인식  시스템 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유 ∙법 집행기관은 AI 기반 데이터 분석을 활용해 범죄 활동에 대한 탐지와 대응 능력을 강화하고, AI  도구로 구조화되지 않은 데이터를 신속히 분석해 비상 상황의 의사결정을 위한 통찰력 확보 가능  ∙기계번역과 같은 AI 기반 도구는 여러 국가가 참여하는 조사에서 원활한 국제협력을 위해서도 필수적 n 그러나 법 집행에서 AI 도구의 효과적이고 책임 있는 활용을 위해 해결되어야 할 기술적 과제 및  다양한 윤리적사회적 우려도 존재 ∙일례로 관할권 간 데이터 수집과 보관 관행의 차이에 따른 데이터셋의 편향으로 인해 AI 산출물의  무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요 ∙데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터  규모와 운영 요구사항에 적응할 수 있는 확장성과 성능을 갖춘 AI 모델도 개발 필요 ∙편향, 개인정보 침해와\n",
      "========================\n",
      "Document 6:\n",
      "증거 수집, 이미지와 비디오 분석, 생체인식  시스템 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유 ∙법 집행기관은 AI 기반 데이터 분석을 활용해 범죄 활동에 대한 탐지와 대응 능력을 강화하고, AI  도구로 구조화되지 않은 데이터를 신속히 분석해 비상 상황의 의사결정을 위한 통찰력 확보 가능  ∙기계번역과 같은 AI 기반 도구는 여러 국가가 참여하는 조사에서 원활한 국제협력을 위해서도 필수적 n 그러나 법 집행에서 AI 도구의 효과적이고 책임 있는 활용을 위해 해결되어야 할 기술적 과제 및  다양한 윤리적사회적 우려도 존재 ∙일례로 관할권 간 데이터 수집과 보관 관행의 차이에 따른 데이터셋의 편향으로 인해 AI 산출물의  무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요 ∙데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터  규모와 운영 요구사항에 적응할 수 있는 확장성과 성능을 갖춘 AI 모델도 개발 필요 ∙편향, 개인정보 침해와\n",
      "========================\n",
      "Document 7:\n",
      "미치는 영향을 조사  n 조사 결과, 근로자들 사이에서는 직장 내 안전이나 임금, 업무 자율성 등의 측면에서 자동화가  긍정적 영향을 미칠 것이란 응답이 우세 ∙자동화가 직장 내 안전에 미치는 영향에 대하여 응답자 44.9%는 긍정적으로 평가했으며 부정적  응답은 12.5%에 불과 ∙자동화가 임금에 미치는 영향은 28.8%가 긍정적, 24.8%는 부정적으로 답했으며, 업무 자율성에  미치는 영향은 37.9%는 긍정적, 19.9%가 부정적이라고 응답 n 자동화 기술에 대한 근로자들의 인식은 대체로 긍정적으로 나타났으나, 국가 별 차이가 존재하며  미국 근로자들이 가장 비관적 태도를 보유 ∙9개국 중 미국에서만 자동화가 임금 및 직업 안정성에 부정적이라는 응답이 긍정적이라는 응답보다  우세(임금: –0.6%, 직업 안정성: -4.6%)* * 긍정적 응답에서 부정적 응답 비율을 뺀 수치 n 직무 유형에서는 복잡한 문제 해결이나 새로운 아이디어가 필요한 작업을 수행하는 사무직\n",
      "========================\n",
      "Document 8:\n",
      "미치는 영향을 조사  n 조사 결과, 근로자들 사이에서는 직장 내 안전이나 임금, 업무 자율성 등의 측면에서 자동화가  긍정적 영향을 미칠 것이란 응답이 우세 ∙자동화가 직장 내 안전에 미치는 영향에 대하여 응답자 44.9%는 긍정적으로 평가했으며 부정적  응답은 12.5%에 불과 ∙자동화가 임금에 미치는 영향은 28.8%가 긍정적, 24.8%는 부정적으로 답했으며, 업무 자율성에  미치는 영향은 37.9%는 긍정적, 19.9%가 부정적이라고 응답 n 자동화 기술에 대한 근로자들의 인식은 대체로 긍정적으로 나타났으나, 국가 별 차이가 존재하며  미국 근로자들이 가장 비관적 태도를 보유 ∙9개국 중 미국에서만 자동화가 임금 및 직업 안정성에 부정적이라는 응답이 긍정적이라는 응답보다  우세(임금: –0.6%, 직업 안정성: -4.6%)* * 긍정적 응답에서 부정적 응답 비율을 뺀 수치 n 직무 유형에서는 복잡한 문제 해결이나 새로운 아이디어가 필요한 작업을 수행하는 사무직\n",
      "========================\n",
      "Document 9:\n",
      "단어를 조합한 카나나는  ‘가장 나다운 AI’를 의미 ∙카카오는 동 브랜드를 자사가 개발하는 주요 AI 모델과 신규 서비스의 이름에 두루 사용할 계획으로,  AI 메이트 서비스 ‘카나나’ 출시 계획도 공개 n 카나나는 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제시하는 ‘AI 메이트’를  지향하며, 개인메이트 ‘나나(nana)’와 그룹메이트 ‘카나(kana)’로 구현 ∙개인메이트 나나는 이용자와 일대일 대화 및 이용자가 참여한 그룹 대화도 기억해 최적화된 개인화  경험을 제공하며, 일례로 그룹대화에서 나눈 컨퍼런스 참석 일정과 준비물을 기억해 이를 잊지 않도록  메시지로 전송 ∙카나는 상주하는 그룹대화 안에서의 대화 내용만 기억해 이용자를 지원하며, 가령 스터디 그룹대화에서  함께 읽은 논문 관련 퀴즈를 내주고 채점과 부연 설명을 제공  ∙카카오는 카나나를 카카오톡과 별개의 앱으로 출시할 예정으로, 연내 사내 테스트 버전 출시를 통해  완성도를 높여갈 계획 n 카카오는 자체 생성AI 모델도 연구개발 중으로, 언어모델은 용량에\n",
      "========================\n",
      "Document 10:\n",
      "단어를 조합한 카나나는  ‘가장 나다운 AI’를 의미 ∙카카오는 동 브랜드를 자사가 개발하는 주요 AI 모델과 신규 서비스의 이름에 두루 사용할 계획으로,  AI 메이트 서비스 ‘카나나’ 출시 계획도 공개 n 카나나는 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제시하는 ‘AI 메이트’를  지향하며, 개인메이트 ‘나나(nana)’와 그룹메이트 ‘카나(kana)’로 구현 ∙개인메이트 나나는 이용자와 일대일 대화 및 이용자가 참여한 그룹 대화도 기억해 최적화된 개인화  경험을 제공하며, 일례로 그룹대화에서 나눈 컨퍼런스 참석 일정과 준비물을 기억해 이를 잊지 않도록  메시지로 전송 ∙카나는 상주하는 그룹대화 안에서의 대화 내용만 기억해 이용자를 지원하며, 가령 스터디 그룹대화에서  함께 읽은 논문 관련 퀴즈를 내주고 채점과 부연 설명을 제공  ∙카카오는 카나나를 카카오톡과 별개의 앱으로 출시할 예정으로, 연내 사내 테스트 버전 출시를 통해  완성도를 높여갈 계획 n 카카오는 자체 생성AI 모델도 연구개발 중으로, 언어모델은 용량에\n",
      "========================\n"
     ]
    },
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Invalid argument provided to Gemini: 400 Developer instruction is not enabled for models/gemini-pro",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgument\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:178\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 Developer instruction is not enabled for models/gemini-pro",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mChatGoogleGenerativeAIError\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m메타의 인공지능에 대해 알려줘\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#print(\"========================\")\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrag_chain_debug\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\langchain_core\\runnables\\base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    287\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    288\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    289\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    290\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    291\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    292\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    293\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    295\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:946\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    922\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    934\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m    935\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m    936\u001b[0m         messages,\n\u001b[0;32m    937\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[0;32m    945\u001b[0m     )\n\u001b[1;32m--> 946\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[0;32m    947\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    949\u001b[0m         generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate_content,\n\u001b[0;32m    950\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[0;32m    951\u001b[0m     )\n\u001b[0;32m    952\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:196\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[1;34m(generation_method, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chat_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\tenacity\\__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\tenacity\\__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\p310\\lib\\site-packages\\langchain_google_genai\\chat_models.py:190\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[1;31mChatGoogleGenerativeAIError\u001b[0m: Invalid argument provided to Gemini: 400 Developer instruction is not enabled for models/gemini-pro"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # query = input(\"질문을 입력하세요: \")\n",
    "    query = \"메타의 인공지능에 대해 알려줘\"\n",
    "    #print(\"========================\")\n",
    "    response = rag_chain_debug.invoke(query)\n",
    "    print()\n",
    "    print()\n",
    "    print(\"Final Response\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d651b8c2-b3e2-4c99-8286-69fbaa15ad51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자연어처리(NLP)는 컴퓨터가 인간 언어를 이해하고 조작할 수 있도록 하는 인공지능(AI)의 한 분야입니다.\n",
      "\n",
      "핵심 목표는 다음과 같습니다.\n",
      "\n",
      "* **텍스트 이해:** 문장과 문서의 의미 파악\n",
      "* **텍스트 생성:** 인간이 읽기 쉬운 텍스트 생성\n",
      "* **텍스트 분류:** 텍스트를 주어진 범주에 할당\n",
      "* **텍스트 번역:** 한 언어에서 다른 언어로 텍스트 변환\n",
      "* **텍스트 검색:** 관련성 있는 텍스트 검색\n",
      "\n",
      "NLP는 다음과 같은 응용 분야에서 사용됩니다.\n",
      "\n",
      "* 검색 엔진\n",
      "* 가상 비서\n",
      "* 고객 서비스 챗봇\n",
      "* 기계 번역\n",
      "* 감정 분석"
     ]
    }
   ],
   "source": [
    "# 프롬프트를 전달하여 결과를 생성합니다.\n",
    "\n",
    "from langchain_teddynote import logging\n",
    "from langchain_teddynote.messages import stream_response\n",
    "answer = model.stream(\"자연어처리에 대해서 간략히 설명해 줘\")\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd898b18-eb02-48b6-886f-86ee76ce6330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310",
   "language": "python",
   "name": "p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
