
### 절대 경로 다운로드
from transformers import AutoModel, AutoTokenizer

# 모델과 토크나이저 로드
model = AutoModel.from_pretrained("jhgan/ko-sbert-nli")
tokenizer = AutoTokenizer.from_pretrained("jhgan/ko-sbert-nli")

# 절대 경로로 저장할 경로 지정 (예: /home/user/models 폴더)
save_path = '/home/pro/VS/models/ko-sbert-nli-model'  # Linux/Mac에서는 슬래시(/) 사용

# 모델과 토크나이저 저장
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

print(f"모델과 토크나이저가 '{save_path}'에 저장되었습니다.")




### 로드
from transformers import AutoModel, AutoTokenizer

# 저장된 모델과 토크나이저 경로 지정
load_path = '/home/pro/VS/models/ko-sbert-nli-model'

# 모델과 토크나이저 로드
model = AutoModel.from_pretrained(load_path)
tokenizer = AutoTokenizer.from_pretrained(load_path)

print(f"모델과 토크나이저가 '{load_path}'에서 로드되었습니다.")







from langchain.embeddings import HuggingFaceEmbeddings

# 원하는 절대경로를 지정
model_path = '/home/pro/VS/models/'

model_name = "jhgan/ko-sbert-nli"
model_kwargs = {'device': 'cpu'}
encode_kwargs = {'normalize_embeddings': True}

ko = HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs,
    model_path=model_path  # 여기에 모델 경로를 지정합니다.
)



from langchain.embeddings import HuggingFaceEmbeddings

model_path = '/home/pro/VS/models/'

ko = HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs,
    model_path=model_path
)

# 모델이 잘 로드되었는지 확인하는 방법
print(ko)