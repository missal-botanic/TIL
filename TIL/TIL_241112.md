
모델이 복잡해지고 파라미터가 많아지면 **과적합(Overfitting)**이 발생하는 이유는 **모델이 훈련 데이터에 너무 잘 맞춰지면서** **일반화 능력이 떨어지기 때문**입니다. 이는 직관적으로 이해할 수 있는 개념인데, 모델이 훈련 데이터의 **세부적인 노이즈**까지 학습하게 되어, **새로운 데이터에 대해 잘 예측하지 못하는 현상**이 발생하기 때문입니다. 반대로 **과소적합(Underfitting)**은 모델이 너무 단순하여 훈련 데이터의 패턴을 제대로 학습하지 못하는 경우입니다.

### 과적합이 발생하는 이유

#### 1. **모델의 복잡도와 파라미터 수**
   - 모델이 복잡해지면 **파라미터의 수가 증가**합니다. 예를 들어, **신경망의 층 수나 뉴런 수**가 많아지면 각 층에서 학습할 수 있는 **패턴의 수**가 늘어나기 때문에, 모델은 훈련 데이터에 있는 **세밀한 패턴과 노이즈까지 학습**하게 됩니다.
   - **파라미터가 많으면** 모델이 훈련 데이터에 대해 **완벽하게 맞출 수 있는 능력**이 커지지만, 이는 **훈련 데이터에 과도하게 적합**되도록 만듭니다. 즉, 모델이 훈련 데이터의 **특이점이나 노이즈**까지 학습해서 새로운 데이터에 대한 일반화 능력이 떨어지는 것입니다.

#### 2. **훈련 데이터의 노이즈**
   - **훈련 데이터**는 실제로 **완벽한 데이터**가 아니기 때문에, **일반적으로 노이즈**가 포함되어 있습니다. 노이즈란, 데이터에서 **패턴이 아닌 우연적인 변동**이나 **측정 오류**를 말합니다.
   - 모델이 너무 복잡하면, 훈련 데이터를 정확히 맞추기 위해 이러한 **노이즈까지 학습**해버릴 수 있습니다. 그러므로 훈련 데이터에서 잘 작동하더라도 새로운 데이터에서는 **노이즈를 학습**한 부분이 **잘못된 예측**을 유발하게 됩니다.

#### 3. **훈련 데이터와 테스트 데이터의 분포 차이**
   - 모델이 훈련 데이터에 과도하게 적합되면, **훈련 데이터와 테스트 데이터**(혹은 실제 환경에서의 데이터)의 분포가 다를 경우, **일반화 성능**이 떨어집니다. 즉, 훈련 데이터에 너무 맞춰진 모델은 **테스트 데이터**에서 잘 예측하지 못하는 **과적합**이 발생합니다.

### 과소적합(Underfitting)의 경우와 차이점

**과소적합**은 모델이 **너무 단순해서** 훈련 데이터의 패턴을 제대로 학습하지 못하는 경우입니다. 이때는 모델이 **훈련 데이터에 잘 맞지 않으므로** 훈련 데이터와 테스트 데이터 모두에서 성능이 좋지 않게 됩니다.

#### 과소적합이 발생하는 이유
- 모델의 **복잡도가 너무 낮을 때** 과소적합이 발생합니다. 예를 들어, 너무 **간단한 선형 모델**을 사용하거나, **층 수가 부족하거나** 뉴런 수가 적은 신경망을 사용하는 경우입니다.
- 이 경우에는 훈련 데이터의 패턴을 제대로 포착하지 못해서, **훈련 오류가 크게 나타나며** 테스트 오류도 높게 나옵니다.

### 과적합과 과소적합의 차이

- **과적합 (Overfitting)**: 모델이 훈련 데이터에 **너무 잘 맞춰져** 테스트 데이터나 새로운 데이터에 대해 **일반화 성능이 떨어지는 현상**입니다. 파라미터 수가 많고 모델이 복잡하면 과적합이 발생할 수 있습니다.
  - 특징: 훈련 데이터에서는 성능이 매우 좋지만, 테스트 데이터에서는 성능이 나쁩니다.
  - 해결 방법: **정규화**, **드롭아웃**, **배치 정규화**, **데이터 증가**(data augmentation), **교차 검증** 등을 사용하여 과적합을 방지할 수 있습니다.

- **과소적합 (Underfitting)**: 모델이 너무 **단순하거나 파라미터가 부족해서** 훈련 데이터에서 중요한 패턴을 잡지 못하는 현상입니다. 모델이 훈련 데이터와 테스트 데이터 모두에서 성능이 낮습니다.
  - 특징: 훈련 데이터에서도 성능이 좋지 않고, 테스트 데이터에서도 성능이 나쁩니다.
  - 해결 방법: **모델 복잡도 증가**, **더 많은 파라미터 추가**, **더 깊은 네트워크 구조**를 사용하여 과소적합을 방지할 수 있습니다.

### 과적합과 과소적합을 구분하는 방법

- **훈련 오류**와 **테스트 오류**를 비교하여 모델의 성능을 평가할 수 있습니다.
   - **과적합**: 훈련 오류는 매우 낮고, 테스트 오류는 높습니다.
   - **과소적합**: 훈련 오류와 테스트 오류가 모두 높은 상태입니다.
  
### 결론

- **모델이 복잡해지면** 파라미터 수가 많아지고, 이로 인해 **훈련 데이터에 과도하게 적합**되는 **과적합**이 발생할 수 있습니다. 이 경우, 모델은 훈련 데이터의 노이즈나 특이점까지 학습하여, 새로운 데이터에 대해서는 **일반화 능력**이 떨어지게 됩니다.
- 반면, **과소적합**은 모델이 너무 단순하여 훈련 데이터의 패턴을 제대로 학습하지 못하는 경우로, 훈련 오류와 테스트 오류가 모두 높은 상황입니다.
  
따라서 모델이 복잡해져서 **파라미터가 많아지면** 과소적합보다는 **과적합**이 발생할 가능성이 높습니다. 과적합을 피하기 위해서는 **정규화** 기법, **조기 종료**, **데이터 증강** 등을 사용하여 모델이 훈련 데이터에 과도하게 적합되지 않도록 해야 합니다.


드랍아웃 : 고루 학습 할 수 있게

하이퍼복릭 탄젠트 : RNN에서 사용
