
복잡도를 높임 : 비선형 문제 해결 <- 활성화 함수 도입 (미분 시키위해 시그모이드 도입, 미분의 목적은 연적파를 계산하기 위해)


다층 퍼셉트론(MLP)에서 **입력에 가중치 \(w\)를 곱하는 이유**는 각 입력 값이 출력에 미치는 영향을 세밀하게 조정하기 위함입니다. 이를 통해 모델은 **복잡한 패턴**을 학습할 수 있습니다.

1. **가중치 곱셈**은 입력 값 \(x_i\)에 대해 가중치 \(w_i\)를 곱하여 **선형 결합**을 만들고, 그 후 **비선형 활성화 함수**를 통해 복잡한 관계를 학습합니다. 곱셈을 사용하면 각 입력의 **중요도**를 동적으로 조절할 수 있어, 모델이 더 정교하게 패턴을 학습할 수 있습니다.

2. **덧셈**만 사용한다면, 입력 간의 차이를 구분할 수 없어 모델이 각 입력의 중요도를 조정하는 데 한계가 생깁니다. 반면, **제곱**을 사용하면 입력 값이 커질수록 영향력이 급격히 커져 학습이 불안정해지거나 과도한 변화를 초래할 수 있습니다. 제곱은 비선형적인 효과를 만들지만, 너무 큰 값을 만들어 모델 학습을 어렵게 만들 수 있습니다.

3. **곱셈**을 사용하면 각 입력이 출력에 미치는 영향을 선형적으로 반영할 수 있으며, 이는 모델 학습에 있어 **안정적이고 효율적**인 방법입니다. 또한, **역전파** 과정에서 가중치 조정이 자연스럽게 이루어져 학습이 잘 진행됩니다.

결론적으로, **곱셈**은 **입력의 중요도를 세밀하게 반영**하고 **학습을 안정적으로** 만드는 중요한 역할을 하므로, 다층 퍼셉트론에서 입력과 출력 간의 관계를 효과적으로 학습할 수 있도록 돕습니다.



**활성화 함수(Activation Function)**는 인공 신경망에서 중요한 역할을 하는 함수로, 각 뉴런이 입력을 받아서 **출력으로 변환**할 때 그 변환 방식에 비선형성을 부여합니다. 즉, **입력 값을 어떤 방식으로 처리할지** 결정하는 함수입니다. 

### 왜 활성화 함수가 필요할까?

1. **비선형성 도입**:
   - 신경망의 목적은 데이터를 학습하고, 패턴을 인식하는 것입니다. **활성화 함수**는 모델에 **비선형성**을 추가하여, 신경망이 복잡하고 다양한 패턴을 학습할 수 있도록 합니다.
   - 만약 활성화 함수가 없거나 **선형 함수**만 사용된다면, 여러 층을 쌓아도 결국 하나의 선형 변환으로 축소될 수 있습니다. 즉, 여러 층을 쌓아도 **단순한 선형 회귀 모델**과 다를 게 없게 되어, 복잡한 패턴을 학습하는 데 한계가 있습니다.

2. **입력에 대한 비선형 처리가 필요**:
   - 현실 세계의 데이터는 일반적으로 **비선형**적인 특성을 가지고 있습니다. 예를 들어, 이미지, 음성, 자연어 등은 복잡한 패턴과 관계를 갖고 있기 때문에, 신경망이 이를 잘 처리할 수 있도록 비선형 함수를 사용합니다.
   
### 활성화 함수의 종류

1. **Sigmoid 함수**:
   - **형태**: \( \sigma(x) = \frac{1}{1 + e^{-x}} \)
   - **특징**: 출력 값이 \(0\)과 \(1\) 사이에 존재합니다. 주로 이진 분류 문제에서 사용됩니다. 하지만 **기울기 소실(gradient vanishing)** 문제로 인해, 깊은 신경망에서는 잘 사용되지 않습니다.
   - **그래프**: S자 형태의 곡선입니다.

2. **Tanh (Hyperbolic Tangent) 함수**:
   - **형태**: \( \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \)
   - **특징**: 출력 값이 \(-1\)과 \(1\) 사이에 존재합니다. Sigmoid보다 **중심이 0**에 가까워 학습이 더 효율적일 수 있지만 여전히 기울기 소실 문제를 겪을 수 있습니다.
   - **그래프**: S자 형태이지만 출력 범위가 \(-1\)에서 \(1\)로 확장된 형태입니다.

3. **ReLU (Rectified Linear Unit)**:
   - **형태**: \( f(x) = \max(0, x) \)
   - **특징**: 음수 값은 \(0\), 양수 값은 그대로 출력합니다. **간단하고 효율적**이며, **기울기 소실 문제를 잘 피할 수 있습니다**. 하지만 **기울기 폭주(gradient explosion)**나 **죽은 뉴런**(Dead Neuron) 문제를 일으킬 수 있습니다. 현재 딥러닝에서 가장 많이 사용되는 활성화 함수입니다.
   - **그래프**: \(x\)가 \(0\) 이하일 때 \(0\), 그 이상일 때는 \(x\)와 동일한 직선입니다.

4. **Leaky ReLU**:
   - **형태**: \( f(x) = \max(\alpha x, x) \) (여기서 \(\alpha\)는 작은 양수)
   - **특징**: ReLU의 변형으로, 음수 입력 값에 대해 아주 작은 기울기를 주어 죽은 뉴런 문제를 일부 해결하려는 함수입니다.

5. **Softmax**:
   - **형태**: \( \text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_j e^{x_j}} \)
   - **특징**: 다중 클래스 분류 문제에서 사용됩니다. 각 클래스의 확률 값을 출력하는 함수로, 모든 출력 값이 \(0\)과 \(1\) 사이에 있으며, 전체 합은 1이 됩니다. 예를 들어, **이미지 분류** 문제에서 각 클래스에 대한 확률을 출력할 때 사용됩니다.

### 활성화 함수의 역할 요약:

1. **비선형성 추가**: 신경망이 복잡한 패턴을 학습할 수 있도록 합니다.
2. **출력 범위 제한**: 예를 들어, Sigmoid나 Tanh는 출력 범위를 제한하여 안정적인 학습을 돕습니다.
3. **기울기 조정**: 학습 과정에서 가중치를 업데이트할 때 **기울기**를 조정하여 **학습 효율**을 높입니다.
4. **특정 문제에 적합**: 분류 문제나 회귀 문제에 따라 적합한 활성화 함수를 선택할 수 있습니다.

### 결론:
활성화 함수는 신경망이 복잡한 관계를 학습하고, 비선형적인 패턴을 잘 모델링할 수 있도록 도와주는 중요한 구성 요소입니다. 다양한 종류의 활성화 함수가 있으며, 각 함수는 특정 문제나 상황에서 더 효과적으로 작동할 수 있습니다.



**실제값 (Ground Truth)**은 모델이 예측하려는 목표 값으로, **훈련 데이터**에 포함된 **정답**을 의미합니다. 즉, **입력 데이터에 대한 참된 출력 값**을 말합니다. 이 값은 모델이 학습하는 동안 **비교 대상**으로 사용되며, 모델이 예측한 출력값과 실제값 간의 차이를 계산하여 **손실 함수(loss function)**를 구합니다.

### 실제값의 출처

1. **훈련 데이터**: 실제값은 일반적으로 **훈련 데이터**에 포함됩니다. 훈련 데이터는 두 가지 주요 구성 요소로 이루어져 있습니다:
   - **입력 데이터 (Features)**: 모델이 예측해야 할 대상에 대한 정보입니다. 예를 들어, 이미지 분류에서는 이미지 자체가 입력 데이터입니다.
   - **실제값 (Ground Truth / Label)**: 모델이 예측하려는 **정답**입니다. 예를 들어, 이미지 분류 문제에서 실제값은 "고양이", "개"와 같은 레이블(label)입니다.

2. **학습 단계에서 사용**: 모델은 훈련 데이터를 통해 실제값을 학습하고, 각 예측에 대해 모델이 예측한 출력과 실제값을 비교합니다. 그 차이를 바탕으로 **손실**을 계산하고, 이를 최소화하려는 방향으로 모델의 가중치를 조정하게 됩니다.

### 손실 함수의 역할

손실 함수는 모델의 예측값과 실제값(정답) 간의 차이를 수치적으로 표현하는 함수입니다. 손실 함수를 계산하려면 모델의 출력과 실제값이 필요합니다.

#### 예시:

1. **회귀 문제 (Regression)**:
   - 예를 들어, **주택 가격 예측** 문제에서, 모델은 집의 특성(예: 크기, 위치 등)을 입력으로 받아 가격을 예측하려고 합니다.
   - 실제값은 각 훈련 샘플에 대해 **정확한 주택 가격**입니다.
   - 손실 함수는 예측된 가격과 실제 주택 가격 간의 차이를 계산합니다. 대표적인 손실 함수로는 **평균 제곱 오차(MSE, Mean Squared Error)**가 있습니다.
   - MSE는 다음과 같이 계산됩니다:
     \[
     MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
     \]
     여기서 \( y_i \)는 실제값, \( \hat{y}_i \)는 모델의 예측값입니다.

2. **분류 문제 (Classification)**:
   - 예를 들어, **이미지 분류** 문제에서 모델은 각 이미지가 특정 클래스(예: 고양이, 개, 자동차 등)에 속할 확률을 예측합니다.
   - 실제값은 각 이미지에 대해 **정확한 클래스 레이블**입니다. 예를 들어, 한 이미지의 실제값은 "고양이"일 수 있습니다.
   - 손실 함수는 예측된 클래스 확률과 실제 클래스 간의 차이를 계산합니다. 대표적인 손실 함수로는 **교차 엔트로피 손실(cross-entropy loss)**이 있습니다.
   - 교차 엔트로피 손실 함수는 다음과 같이 계산됩니다:
     \[
     \text{Cross-Entropy} = - \sum_{i=1}^{C} y_i \log(\hat{y}_i)
     \]
     여기서 \(C\)는 클래스의 수, \( y_i \)는 실제 클래스에 대한 one-hot 인코딩 값, \( \hat{y}_i \)는 예측된 확률값입니다.

### 실제값이 중요한 이유

1. **모델 학습의 기준**: 모델은 훈련 데이터의 **실제값**과 예측값을 비교하면서 가중치를 업데이트합니다. 손실 함수를 사용해 **실제값**과 **예측값** 간의 차이를 최소화하려고 합니다.
   
2. **모델의 성능 평가**: 실제값을 기준으로 모델의 예측 성능을 평가합니다. 예측이 정확하다면 손실 값이 작고, 예측이 부정확하다면 손실 값이 커집니다.

3. **검증 및 테스트**: 훈련 데이터 외에도 **검증 데이터**나 **테스트 데이터**를 사용하여 모델의 성능을 평가합니다. 이 데이터 역시 실제값이 포함되어 있으며, 이를 통해 모델이 얼마나 잘 일반화되었는지를 확인할 수 있습니다.

### 요약

- **실제값**은 **훈련 데이터**에 포함된 **정답** 값으로, 모델이 예측해야 하는 값입니다.
- 모델은 **출력층**에서 예측한 값과 실제값을 비교하여 **손실 함수**를 계산하고, 이 손실을 최소화하려고 학습을 진행합니다.
- 손실 함수는 예측과 실제값 간의 차이를 수치적으로 표현하여, 모델이 학습 과정에서 개선될 수 있도록 돕습니다.




모델이 복잡해지고 파라미터가 많아지면 **과적합(Overfitting)**이 발생하는 이유는 **모델이 훈련 데이터에 너무 잘 맞춰지면서** **일반화 능력이 떨어지기 때문**입니다. 이는 직관적으로 이해할 수 있는 개념인데, 모델이 훈련 데이터의 **세부적인 노이즈**까지 학습하게 되어, **새로운 데이터에 대해 잘 예측하지 못하는 현상**이 발생하기 때문입니다. 반대로 **과소적합(Underfitting)**은 모델이 너무 단순하여 훈련 데이터의 패턴을 제대로 학습하지 못하는 경우입니다.

### 과적합이 발생하는 이유

#### 1. **모델의 복잡도와 파라미터 수**
   - 모델이 복잡해지면 **파라미터의 수가 증가**합니다. 예를 들어, **신경망의 층 수나 뉴런 수**가 많아지면 각 층에서 학습할 수 있는 **패턴의 수**가 늘어나기 때문에, 모델은 훈련 데이터에 있는 **세밀한 패턴과 노이즈까지 학습**하게 됩니다.
   - **파라미터가 많으면** 모델이 훈련 데이터에 대해 **완벽하게 맞출 수 있는 능력**이 커지지만, 이는 **훈련 데이터에 과도하게 적합**되도록 만듭니다. 즉, 모델이 훈련 데이터의 **특이점이나 노이즈**까지 학습해서 새로운 데이터에 대한 일반화 능력이 떨어지는 것입니다.

#### 2. **훈련 데이터의 노이즈**
   - **훈련 데이터**는 실제로 **완벽한 데이터**가 아니기 때문에, **일반적으로 노이즈**가 포함되어 있습니다. 노이즈란, 데이터에서 **패턴이 아닌 우연적인 변동**이나 **측정 오류**를 말합니다.
   - 모델이 너무 복잡하면, 훈련 데이터를 정확히 맞추기 위해 이러한 **노이즈까지 학습**해버릴 수 있습니다. 그러므로 훈련 데이터에서 잘 작동하더라도 새로운 데이터에서는 **노이즈를 학습**한 부분이 **잘못된 예측**을 유발하게 됩니다.

#### 3. **훈련 데이터와 테스트 데이터의 분포 차이**
   - 모델이 훈련 데이터에 과도하게 적합되면, **훈련 데이터와 테스트 데이터**(혹은 실제 환경에서의 데이터)의 분포가 다를 경우, **일반화 성능**이 떨어집니다. 즉, 훈련 데이터에 너무 맞춰진 모델은 **테스트 데이터**에서 잘 예측하지 못하는 **과적합**이 발생합니다.

### 과소적합(Underfitting)의 경우와 차이점

**과소적합**은 모델이 **너무 단순해서** 훈련 데이터의 패턴을 제대로 학습하지 못하는 경우입니다. 이때는 모델이 **훈련 데이터에 잘 맞지 않으므로** 훈련 데이터와 테스트 데이터 모두에서 성능이 좋지 않게 됩니다.

#### 과소적합이 발생하는 이유
- 모델의 **복잡도가 너무 낮을 때** 과소적합이 발생합니다. 예를 들어, 너무 **간단한 선형 모델**을 사용하거나, **층 수가 부족하거나** 뉴런 수가 적은 신경망을 사용하는 경우입니다.
- 이 경우에는 훈련 데이터의 패턴을 제대로 포착하지 못해서, **훈련 오류가 크게 나타나며** 테스트 오류도 높게 나옵니다.

### 과적합과 과소적합의 차이

- **과적합 (Overfitting)**: 모델이 훈련 데이터에 **너무 잘 맞춰져** 테스트 데이터나 새로운 데이터에 대해 **일반화 성능이 떨어지는 현상**입니다. 파라미터 수가 많고 모델이 복잡하면 과적합이 발생할 수 있습니다.
  - 특징: 훈련 데이터에서는 성능이 매우 좋지만, 테스트 데이터에서는 성능이 나쁩니다.
  - 해결 방법: **정규화**, **드롭아웃**, **배치 정규화**, **데이터 증가**(data augmentation), **교차 검증** 등을 사용하여 과적합을 방지할 수 있습니다.

- **과소적합 (Underfitting)**: 모델이 너무 **단순하거나 파라미터가 부족해서** 훈련 데이터에서 중요한 패턴을 잡지 못하는 현상입니다. 모델이 훈련 데이터와 테스트 데이터 모두에서 성능이 낮습니다.
  - 특징: 훈련 데이터에서도 성능이 좋지 않고, 테스트 데이터에서도 성능이 나쁩니다.
  - 해결 방법: **모델 복잡도 증가**, **더 많은 파라미터 추가**, **더 깊은 네트워크 구조**를 사용하여 과소적합을 방지할 수 있습니다.

### 과적합과 과소적합을 구분하는 방법

- **훈련 오류**와 **테스트 오류**를 비교하여 모델의 성능을 평가할 수 있습니다.
   - **과적합**: 훈련 오류는 매우 낮고, 테스트 오류는 높습니다.
   - **과소적합**: 훈련 오류와 테스트 오류가 모두 높은 상태입니다.
  
### 결론

- **모델이 복잡해지면** 파라미터 수가 많아지고, 이로 인해 **훈련 데이터에 과도하게 적합**되는 **과적합**이 발생할 수 있습니다. 이 경우, 모델은 훈련 데이터의 노이즈나 특이점까지 학습하여, 새로운 데이터에 대해서는 **일반화 능력**이 떨어지게 됩니다.
- 반면, **과소적합**은 모델이 너무 단순하여 훈련 데이터의 패턴을 제대로 학습하지 못하는 경우로, 훈련 오류와 테스트 오류가 모두 높은 상황입니다.
  
따라서 모델이 복잡해져서 **파라미터가 많아지면** 과소적합보다는 **과적합**이 발생할 가능성이 높습니다. 과적합을 피하기 위해서는 **정규화** 기법, **조기 종료**, **데이터 증강** 등을 사용하여 모델이 훈련 데이터에 과도하게 적합되지 않도록 해야 합니다.


드랍아웃 : 고루 학습 할 수 있게