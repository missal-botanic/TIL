분류를 하기 위한 첫 스텝은 Feature와 Label을 파악하는 것이라고 했습니다. Label은 우리가 원하는 분류 결과입니다

Label 결과에 영항을 주는 요소가 Feature입니다

X = Feature -> 광고성 단어 개수

y = Label = 1 -> 스팸 메일인 경우 
y = Label = 0 -> 스팸 메일이 아닌 경우 

### 평가방법

 Training data set을 통해 classifier 모델을 훈련
 classfier 모델의 성능(performance)을 평가
 성능(performance)은 정밀도(accuracy),  정확성(Precision), 재현율(Recall) 등으로 측정

 df_filter =  encode_labels(X, X2, y, to_numpy=True)

### ncode_labels 함수
```py
X_encoded, X2_encoded, y_encoded = encode_labels(X, X2, y, to_numpy=True)
#X_combined = list(zip(X_encoded, X2_encoded)) #튜플
X_combined = np.column_stack((X_encoded, X2_encoded)) #2D 배열
```

### 파이썬 코드 규칙
```py
# 1.
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

# 2.
X_train_scaled = scaler.fit_transform(X_train) 
X_test_scaled = scaler.transform(X_test)        


# 3.
X_train_scaled = scaler.fit_transform(X_train)  
X_test_scaled = scaler.fit_transform(X_test)

# 1번과 2번은 같지만 
# 3번은 다르다

```
### 혼동행열 예시

[[TN, FP],
 [FN, TP]]



 # 1. 마지막이 labels 인경우
#X = dataset.iloc[:, :-1].values  # 특성
#labels = dataset.iloc[:, -1].values  # 레이블

cluster 군집

유사도 함수 - > 색, 크기, 모양 

비지도는 지도 학습의 전처리 방법으로 쓰이기도 한다.


훈련 세트 정확도: 0.981
테스트 세트 정확도: 0.698


---
### Lasso


#### 학습 분리
X, y_labels = split_features_and_target(df_encoded, 'survived')  # 특징과 타겟 분리
X_train, X_test, y_train, y_test = train_test_split(X, y_labels, test_size=0.3, random_state=109)

#### 스케일화
#X_train_scaled, X_test_scaled = scale_data_SS(X_train, X_test)
X_train_scaled, X_test_scaled = scale_data_MMS(X_train, X_test)

from sklearn.linear_model import Lasso

#### 모델 초기화 및 훈련
regression = Lasso(alpha=0.1)  # alpha는 λ에 해당
regression.fit(X, y_labels)

coefficients = regression.coef_
print(coefficients)

#### 0이 아닌 계수를 가진 feature만 선택
important_features = [i for i in range(len(coefficients)) if coefficients[i] != 0]
print("선택된 feature의 인덱스:", important_features)
selected_column_names = [df.columns[i] for i in important_features]
print("선택된 feature의 열 이름:", selected_column_names,"전체 컬럼 이름" ,X.columns.tolist())

X_selected = X.iloc[:, important_features]
print("선택된 feature의 데이터:\n", selected_data)



###임계값 조절

from sklearn.metrics import confusion_matrix

#### 예측 확률을 얻습니다.
y_prob = model.predict_proba(X_test)[:, 1]  # Positive 클래스의 확률을 선택합니다.

#### 원하는 임계값을 설정합니다.
threshold = 0.2  # 예: 0.5로 설정

#### 임계값에 따라 예측을 만듭니다.
y_pred_custom = (y_prob >= threshold).astype(int)
print(y_pred_custom)


print(confusion_matrix(y_test, y_pred_custom))
print("예측 확률 통계량:", np.min(y_prob), np.max(y_prob), np.mean(y_pred_custom))






### K 폴트 교차 검증
```py
X, y_labels = split_features_and_target(df_encoded_scaled, 'survived')  # 특징과 타겟 분리
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
logreg = LogisticRegression()
y_labels = (y_labels >= 0.5).astype(int)
# k=5로 k-fold cross validation 수행
scores = cross_val_score(logreg, X, y_labels, cv=5)
print("교차 검증 점수: ", scores)
```


























