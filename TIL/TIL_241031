## 본 데이터의 특징을 나타는 도구

### 벡터

스칼라

시점, 종점

크기: 화살표 길이
방향: 화살표 방향 

인공지능의 벡터 = 위치벡터(벡터의 종점)

1. 길이 : 피타고라스 정의

2.방향은 코사인세타


1. 벡터의 내적(inner product . dot)(PCA) : 벡터가 다른 벡터에 기여하는 정도

2. 위치벡터 :  두 x 곱하고 y 곱 하서 더하면 된다. 0보다 크면 같은 반향, 0 이면 수직, 0보다 작으면 다른 방향

### 평균, 분산, 표준편차 

평균 수식을 사용한 표준편차 수식은 그 값이 0이 되는 것을 막기 위해 '제곱'을 실행함 -> 루트(제곱근 원위치)로 다시 내림
'본인의 값'에서 '평균'을 빼고 제곱한 갑들을 나눈다.

평균 + 표준편차, 평균 - 표준편차 = 하위 |-16%|-34%| 평균 |+34%|+16%| = 68%

### 표준화 (같은 기준 + 이상치 확인)

컴퓨터는 큰수만 인정, 점수 90/100 과 180/200이 다르게 해석 = 인공지능으 볼륨(Volume)만 본다. 

데이터를 0(평균), 표준편차(1)로 변환

정의는 Z




1. 평균(Mean)이 0

    편균은 데이터의 평균을 의미합니다. 편균이 0이라는 것은 데이터의 값들이 평균적으로 0에 중심을 두고 있다는 것을 의미합니다.
    예를 들어, 데이터가 -1, 0, 1이라면 이 세 수의 평균은 0입니다.

2. 표준편차(Standard Deviation)가 1

    표준편차는 데이터가 평균에서 얼마나 퍼져 있는지를 나타내는 지표입니다. 표준편차가 1이라는 것은 데이터가 평균(0)에서 평균적으로 1 단위 정도 떨어져 있다는 의미입니다.
    즉, 대부분의 데이터가 -1에서 1 사이에 분포할 가능성이 높습니다.

정리

    편균이 0이고 표준편차가 1인 데이터는 정규분포의 표준정규분포를 나타냅니다. 이 경우, 분포의 모양은 종 모양을 하고 있으며, 68%의 데이터가 평균 ±1 표준편차 내에 존재하고, 95%는 ±2 표준편차 내에 존재합니다.




 ## 두데이터의 관계 분석

 ### 공분산 (Corariance)   

 공분산 둘이 하나 늘때 하나 같이 늘어난다.
 
공분산이 음수가 하나가 될 때 하나 감소

선에 붙을수록 공분산이 크다. 

하나가 늘때 하나가 더 확실히 는다.

하나가 늘때 하나가 확 감소 한다.

### 표준화 -> 상관 계수

음의 상관 관계-1 < r <0 [\]
독립 서로 영향을 주지 않는다 r = 0 [o]
양의 상관 관계 0<r<1 [/]

0.8 높다 , 0.6 일반, 0~0.2 관계 없다.[1이 나올경우 잘못될 가능성 크다]

## 선형회기 두 데이터를 관계 뿐만 아니라 더 정확한 수식(방적식)을 알고 싶다.

'에러'를 제거한 두 데이터 간의 관계 도출

선형회기 유도(기울기)


