ML_학습, 예측, 정확도, 평가
=============

### 분리
X_train, X_test, y_train, y_test = train_test_split(X, y)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

------------

### 학습
```py
model.fit(X,y)
```
X는 여러 특성(2D 배열): 여러 샘플과 여러 특성을 고려해야 하기 때문에 2D 배열 형식이 필요합니다.
y는 단일 결과(1D 배열): 각 샘플에 대해 하나의 목표 값만 필요하므로 1D 배열 형식이 필요합니다.

###  DBSCAN 다양한 eps와 min_samples 값 시도
```py
eps_values = [3, 5, 7, 10]
min_samples_values = [3, 5, 7, 10]

for eps in eps_values:
    for min_samples in min_samples_values:
        dbscan = DBSCAN(eps=eps, min_samples=min_samples)
        df['Cluster'] = dbscan.fit_predict(X)
        
        plt.figure(figsize=(10, 7))
        sns.scatterplot(x='Annual Income (k$)', y='Spending Score (1-100)', hue='Cluster', data=df, palette='viridis')
        plt.title(f'DBSCAN Clustering (eps={eps}, min_samples={min_samples})')
        plt.show()
```

------------

### 예측
```py
y_pred = model.predict(X_test)
```

------------

### 평가 

### 모델평가
```py
from sklearn.metrics import silhouette_score

silhouette_avg = silhouette_score(X_scaled, y_hc) # 실루엣 점수 계산
print(f'Silhouette Score: {silhouette_avg}')
```

### 정확도 계산 (예측 결과와 실제 레이블을 비교하여 모델의 성능(정확도)을 평가)
```py
accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
```
accuracy_score(y_test, y_pred)는 모델의 예측 결과와 실제 레이블을 비교하여 정확도를 계산합니다.
y_test는 테스트 데이터에 대한 실제 레이블, y_pred는 모델이 예측한 레이블입니다.
이 함수는 올바르게 예측한 샘플의 비율을 계산하여 정확도(accuracy)를 반환합니다.
즉, (올바르게 예측한 샘플 수) / (전체 샘플 수)로 계산되며, 0과 1 사이의 값이 반환됩니다.

### 종합적인 성능 보고서
```py
classification_report(y_test, y_pred)
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
```
 Scikit-learn 라이브러리의 함수로, 모델의 예측 성능을 종합적으로 평가하는 보고서를 생성합니다.
 
Precision: 올바르게 예측한 양성 샘플 수 / (올바르게 예측한 양성 샘플 수 + 잘못 예측한 양성 샘플 수)
양성으로 예측한 것 중 실제로 양성인 비율입니다.
Recall: 올바르게 예측한 양성 샘플 수 / (올바르게 예측한 양성 샘플 수 + 잘못 예측한 음성 샘플 수)
실제 양성 샘플 중에서 올바르게 예측한 비율입니다.
F1-score: Precision과 Recall의 조화 평균으로, 두 지표의 균형을 나타냅니다.
Support: 각 클래스에 대한 실제 샘플 수입니다.

f-string을 사용하면 중괄호 {} 안에 변수를 직접 넣을 수 있어, 문자열을 동적으로 생성할 수 있습니다

### XGBoost
```py
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
print(f'XGBoost 모델의 MSE: {mse_xgb}')
```

### model.score(X_te,y_te) 점수
 
### model.corrcoef(model.predict(X_te),y_te) 상관계수

### MSE = mean_squared_error(model.predict(X_te),y_te)
### NMSE = MSE/np.max(y_te) , np.mean(y_te), np.max(y_te)-np.min(y_te)

### .feature_importances__
### np.argmax(model.feature_importances__)

### 랜덤포레스트(앙상블) 결정 트리 상위호환 많이 쓰인다.

