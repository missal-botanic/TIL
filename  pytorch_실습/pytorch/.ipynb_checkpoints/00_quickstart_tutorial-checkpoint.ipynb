{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uc2e4 \ub54c\uc5d0\ub294 \n# https://tutorials.pytorch.kr/beginner/colab \ub97c \ucc38\uace0\ud558\uc138\uc694.\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[\ud30c\uc774\ud1a0\uce58(PyTorch) \uae30\ubcf8 \uc775\ud788\uae30](intro.html) \\|\\| **\ube60\ub978 \uc2dc\uc791** \\|\\|\n[\ud150\uc11c(Tensor)](tensorqs_tutorial.html) \\|\\| [Dataset\uacfc\nDataloader](data_tutorial.html) \\|\\|\n[\ubcc0\ud615(Transform)](transforms_tutorial.html) \\|\\| [\uc2e0\uacbd\ub9dd \ubaa8\ub378\n\uad6c\uc131\ud558\uae30](buildmodel_tutorial.html) \\|\\|\n[Autograd](autogradqs_tutorial.html) \\|\\|\n[\ucd5c\uc801\ud654(Optimization)](optimization_tutorial.html) \\|\\| [\ubaa8\ub378 \uc800\uc7a5\ud558\uace0\n\ubd88\ub7ec\uc624\uae30](saveloadrun_tutorial.html)\n\n\ube60\ub978 \uc2dc\uc791(Quickstart)\n=====================\n\n\uc774\ubc88 \uc7a5\uc5d0\uc11c\ub294 \uae30\uacc4 \ud559\uc2b5\uc758 \uc77c\ubc18\uc801\uc778 \uc791\uc5c5\ub4e4\uc744 \uc704\ud55c API\ub97c \ud1b5\ud574 \uc2e4\ud589\ub429\ub2c8\ub2e4.\n\ub354 \uc790\uc138\ud788 \uc54c\uc544\ubcf4\ub824\uba74 \uac01 \uc7a5(section)\uc758 \ub9c1\ud06c\ub97c \ucc38\uace0\ud558\uc138\uc694.\n\n\ub370\uc774\ud130 \uc791\uc5c5\ud558\uae30\n---------------\n\n\ud30c\uc774\ud1a0\uce58(PyTorch)\uc5d0\ub294 [\ub370\uc774\ud130 \uc791\uc5c5\uc744 \uc704\ud55c \uae30\ubcf8\n\uc694\uc18c](https://pytorch.org/docs/stable/data.html) \ub450\uac00\uc9c0\uc778\n`torch.utils.data.DataLoader` \uc640 `torch.utils.data.Dataset` \uac00 \uc788\uc2b5\ub2c8\ub2e4.\n`Dataset` \uc740 \uc0d8\ud50c\uacfc \uc815\ub2f5(label)\uc744 \uc800\uc7a5\ud558\uace0, `DataLoader` \ub294 `Dataset` \uc744\n\uc21c\ud68c \uac00\ub2a5\ud55c \uac1d\uccb4(iterable)\ub85c \uac10\uc309\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyTorch\ub294 [TorchText](https://pytorch.org/text/stable/index.html),\n[TorchVision](https://pytorch.org/vision/stable/index.html) \ubc0f\n[TorchAudio](https://pytorch.org/audio/stable/index.html) \uc640 \uac19\uc774 \ub3c4\uba54\uc778\n\ud2b9\ud654 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \ub370\uc774\ud130\uc14b\uacfc \ud568\uaed8 \uc81c\uacf5\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294\nTorchVision \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n`torchvision.datasets` \ubaa8\ub4c8\uc740 CIFAR, COCO \ub4f1\uacfc \uac19\uc740 \ub2e4\uc591\ud55c \uc2e4\uc81c\n\ube44\uc804(vision) \ub370\uc774\ud130\uc5d0 \ub300\ud55c `Dataset`([\uc804\uccb4 \ubaa9\ub85d\uc740\n\uc5ec\uae30](https://pytorch.org/vision/stable/datasets.html))\uc744 \ud3ec\ud568\ud558\uace0\n\uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 FasionMNIST \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ubaa8\ub4e0\nTorchVision `Dataset` \uc740 \uc0d8\ud50c\uacfc \uc815\ub2f5\uc744 \uac01\uac01 \ubcc0\uacbd\ud558\uae30 \uc704\ud55c `transform` \uacfc\n`target_transform` \uc758 \ub450 \uc778\uc790\ub97c \ud3ec\ud568\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uacf5\uac1c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud559\uc2b5 \ub370\uc774\ud130\ub97c \ub0b4\ub824\ubc1b\uc2b5\ub2c8\ub2e4.\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n)\n\n# \uacf5\uac1c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\ub97c \ub0b4\ub824\ubc1b\uc2b5\ub2c8\ub2e4.\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Dataset` \uc744 `DataLoader` \uc758 \uc778\uc790\ub85c \uc804\ub2ec\ud569\ub2c8\ub2e4. \uc774\ub294 \ub370\uc774\ud130\uc14b\uc744 \uc21c\ud68c\n\uac00\ub2a5\ud55c \uac1d\uccb4(iterable)\ub85c \uac10\uc2f8\uace0, \uc790\ub3d9\ud654\ub41c \ubc30\uce58(batch), \uc0d8\ud50c\ub9c1(sampling),\n\uc11e\uae30(shuffle) \ubc0f \ub2e4\uc911 \ud504\ub85c\uc138\uc2a4\ub85c \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30(multiprocess data\nloading)\ub97c \uc9c0\uc6d0\ud569\ub2c8\ub2e4. \uc5ec\uae30\uc11c\ub294 \ubc30\uce58 \ud06c\uae30(batch size)\ub97c 64\ub85c \uc815\uc758\ud569\ub2c8\ub2e4.\n\uc989, \ub370\uc774\ud130\ub85c\ub354(dataloader) \uac1d\uccb4\uc758 \uac01 \uc694\uc18c\ub294 64\uac1c\uc758 \ud2b9\uc9d5(feature)\uacfc\n\uc815\ub2f5(label)\uc744 \ubb36\uc74c(batch)\uc73c\ub85c \ubc18\ud658\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n\n# \ub370\uc774\ud130\ub85c\ub354\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size)\n\nfor X, y in test_dataloader:\n    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[PyTorch\uc5d0\uc11c \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc624\ub294 \ubc29\ubc95](data_tutorial.html) \uc744 \uc790\uc138\ud788\n\uc54c\uc544\ubcf4\uc138\uc694.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \ub9cc\ub4e4\uae30\n===========\n\nPyTorch\uc5d0\uc11c \uc2e0\uacbd\ub9dd \ubaa8\ub378\uc740\n[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n\uc744 \uc0c1\uc18d\ubc1b\ub294 \ud074\ub798\uc2a4(class)\ub97c \uc0dd\uc131\ud558\uc5ec \uc815\uc758\ud569\ub2c8\ub2e4. `__init__` \ud568\uc218\uc5d0\uc11c\n\uc2e0\uacbd\ub9dd\uc758 \uacc4\uce35(layer)\ub4e4\uc744 \uc815\uc758\ud558\uace0 `forward` \ud568\uc218\uc5d0\uc11c \uc2e0\uacbd\ub9dd\uc5d0 \ub370\uc774\ud130\ub97c\n\uc5b4\ub5bb\uac8c \uc804\ub2ec\ud560\uc9c0 \uc9c0\uc815\ud569\ub2c8\ub2e4. \uac00\ub2a5\ud55c \uacbd\uc6b0 GPU \ub610\ub294 MPS\ub85c \uc2e0\uacbd\ub9dd\uc744 \uc774\ub3d9\uc2dc\ucf1c\n\uc5f0\uc0b0\uc744 \uac00\uc18d(accelerate)\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ud560 CPU\ub098 GPU, MPS \uc7a5\uce58\ub97c \uc5bb\uc2b5\ub2c8\ub2e4.\ndevice = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")\n\n# \ubaa8\ub378\uc744 \uc815\uc758\ud569\ub2c8\ub2e4.\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = NeuralNetwork().to(device)\nprint(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[PyTorch\uc5d0\uc11c \uc2e0\uacbd\ub9dd\uc744 \uc815\uc758\ud558\ub294 \ubc29\ubc95](buildmodel_tutorial.html) \uc744 \uc790\uc138\ud788\n\uc54c\uc544\ubcf4\uc138\uc694.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \ub9e4\uac1c\ubcc0\uc218 \ucd5c\uc801\ud654\ud558\uae30\n========================\n\n\ubaa8\ub378\uc744 \ud559\uc2b5\ud558\ub824\uba74 [\uc190\uc2e4 \ud568\uc218(loss\nfunction)](https://pytorch.org/docs/stable/nn.html#loss-functions) \uc640\n[\uc635\ud2f0\ub9c8\uc774\uc800(optimizer)](https://pytorch.org/docs/stable/optim.html) \uac00\n\ud544\uc694\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uac01 \ud559\uc2b5 \ub2e8\uacc4(training loop)\uc5d0\uc11c \ubaa8\ub378\uc740 (\ubc30\uce58(batch)\ub85c \uc81c\uacf5\ub418\ub294) \ud559\uc2b5\n\ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc608\uce21\uc744 \uc218\ud589\ud558\uace0, \uc608\uce21 \uc624\ub958\ub97c \uc5ed\uc804\ud30c\ud558\uc5ec \ubaa8\ub378\uc758\n\ub9e4\uac1c\ubcc0\uc218\ub97c \uc870\uc815\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # \uc608\uce21 \uc624\ub958 \uacc4\uc0b0\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # \uc5ed\uc804\ud30c\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), (batch + 1) * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378\uc774 \ud559\uc2b5\ud558\uace0 \uc788\ub294\uc9c0\ub97c \ud655\uc778\ud558\uae30 \uc704\ud574 \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc14b\uc73c\ub85c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744\n\ud655\uc778\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \ub2e8\uacc4\ub294 \uc5ec\ub7ec\ubc88\uc758 \ubc18\ubcf5 \ub2e8\uacc4 (*\uc5d0\ud3ed(epochs)*) \ub97c \uac70\uccd0\uc11c \uc218\ud589\ub429\ub2c8\ub2e4. \uac01\n\uc5d0\ud3ed\uc5d0\uc11c\ub294 \ubaa8\ub378\uc740 \ub354 \ub098\uc740 \uc608\uce21\uc744 \ud558\uae30 \uc704\ud574 \ub9e4\uac1c\ubcc0\uc218\ub97c \ud559\uc2b5\ud569\ub2c8\ub2e4. \uac01\n\uc5d0\ud3ed\ub9c8\ub2e4 \ubaa8\ub378\uc758 \uc815\ud655\ub3c4(accuracy)\uc640 \uc190\uc2e4(loss)\uc744 \ucd9c\ub825\ud569\ub2c8\ub2e4; \uc5d0\ud3ed\ub9c8\ub2e4\n\uc815\ud655\ub3c4\uac00 \uc99d\uac00\ud558\uace0 \uc190\uc2e4\uc774 \uac10\uc18c\ud558\ub294 \uac83\uc744 \ubcf4\ub824\uace0 \ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[\ubaa8\ub378\uc744 \ud559\uc2b5\ud558\ub294 \ubc29\ubc95](optimization_tutorial.html) \uc744 \uc790\uc138\ud788 \uc54c\uc544\ubcf4\uc138\uc694.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \uc800\uc7a5\ud558\uae30\n=============\n\n\ubaa8\ub378\uc744 \uc800\uc7a5\ud558\ub294 \uc77c\ubc18\uc801\uc778 \ubc29\ubc95\uc740 (\ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218\ub4e4\uc744 \ud3ec\ud568\ud558\uc5ec) \ub0b4\ubd80 \uc0c1\ud0dc\n\uc0ac\uc804(internal state dictionary)\uc744 \uc9c1\ub82c\ud654(serialize)\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\nprint(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \ubd88\ub7ec\uc624\uae30\n=============\n\n\ubaa8\ub378\uc744 \ubd88\ub7ec\uc624\ub294 \uacfc\uc815\uc5d0\ub294 \ubaa8\ub378 \uad6c\uc870\ub97c \ub2e4\uc2dc \ub9cc\ub4e4\uace0 \uc0c1\ud0dc \uc0ac\uc804\uc744 \ubaa8\ub378\uc5d0\n\ubd88\ub7ec\uc624\ub294 \uacfc\uc815\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork().to(device)\nmodel.load_state_dict(torch.load(\"model.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c \uc774 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud574\uc11c \uc608\uce21\uc744 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "classes = [\n    \"T-shirt/top\",\n    \"Trouser\",\n    \"Pullover\",\n    \"Dress\",\n    \"Coat\",\n    \"Sandal\",\n    \"Shirt\",\n    \"Sneaker\",\n    \"Bag\",\n    \"Ankle boot\",\n]\n\nmodel.eval()\nx, y = test_data[0][0], test_data[0][1]\nwith torch.no_grad():\n    x = x.to(device)\n    pred = model(x)\n    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[\ubaa8\ub378\uc744 \uc800\uc7a5\ud558\uace0 \ubd88\ub7ec\uc624\ub294 \ubc29\ubc95](saveloadrun_tutorial.html) \uc744 \uc790\uc138\ud788\n\uc54c\uc544\ubcf4\uc138\uc694.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}